# 7. Dry Runs

## ğŸ¯ Learning Objectives
- [ ] Master `helm upgrade --dry-run --debug` command
- [ ] Understand dry-run output and interpretation
- [ ] Learn to validate configurations before deployment
- [ ] Practice safe change validation workflows
- [ ] Implement pre-deployment testing strategies

## ğŸ“‹ Basic Dry-Run Commands

### Simple Dry-Run
```bash
# Test upgrade without applying changes
helm upgrade my-release bitnami/nginx \
  --set replicaCount=3 \
  --dry-run

# Dry-run with debug output
helm upgrade my-release bitnami/nginx \
  --set replicaCount=3 \
  --dry-run \
  --debug
```

### Dry-Run with Values File
```bash
# Test upgrade with values file
helm upgrade my-release bitnami/nginx \
  -f production-values.yaml \
  --dry-run \
  --debug
```

### Install Dry-Run
```bash
# Test new installation
helm install test-release bitnami/nginx \
  -f my-values.yaml \
  --dry-run \
  --debug
```

## ğŸ” Understanding Dry-Run Output

### Sample Dry-Run Output
```yaml
# Dry-run output shows what would be applied
NAME: my-release
LAST DEPLOYED: Mon Jan 15 14:30:00 2024
NAMESPACE: default
STATUS: pending-upgrade
REVISION: 2
TEST SUITE: None
USER-SUPPLIED VALUES:
replicaCount: 3

COMPUTED VALUES:
autoscaling:
  enabled: false
image:
  pullPolicy: IfNotPresent
  repository: nginx
  tag: 1.25.3
replicaCount: 3
service:
  port: 80
  type: ClusterIP

HOOKS:
MANIFEST:
---
# Source: nginx/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-release-nginx
  labels:
    app.kubernetes.io/name: nginx
    app.kubernetes.io/instance: my-release
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: nginx
    app.kubernetes.io/instance: my-release
---
# Source: nginx/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-release-nginx
  labels:
    app.kubernetes.io/name: nginx
    app.kubernetes.io/instance: my-release
spec:
  replicas: 3  # This changed from 1 to 3
  selector:
    matchLabels:
      app.kubernetes.io/name: nginx
      app.kubernetes.io/instance: my-release
# ... rest of deployment manifest
```

### Key Sections Explained

#### USER-SUPPLIED VALUES
```yaml
# Shows values explicitly provided by user
USER-SUPPLIED VALUES:
replicaCount: 3
image:
  tag: "1.26.0"
```

#### COMPUTED VALUES
```yaml
# Shows final merged values (user + defaults)
COMPUTED VALUES:
autoscaling:
  enabled: false
image:
  pullPolicy: IfNotPresent
  repository: nginx
  tag: "1.26.0"
replicaCount: 3
```

#### MANIFEST
```yaml
# Shows actual Kubernetes manifests to be applied
MANIFEST:
---
apiVersion: apps/v1
kind: Deployment
# ... deployment specification
```

## ğŸ› ï¸ Advanced Dry-Run Techniques

### Template-Only Dry-Run
```bash
# Generate templates without release context
helm template my-release bitnami/nginx \
  -f values.yaml \
  --debug
```

### Specific Resource Dry-Run
```bash
# Focus on specific resources with filtering
helm upgrade my-release bitnami/nginx \
  --dry-run \
  --debug | grep -A 20 "kind: Deployment"
```

### Multiple Environment Validation
```bash
# Validate different environment configurations
for env in dev staging prod; do
  echo "=== Validating $env environment ==="
  helm upgrade my-release bitnami/nginx \
    -f base-values.yaml \
    -f ${env}-values.yaml \
    --dry-run > ${env}-dry-run.yaml
done
```

## ğŸ“Š Dry-Run Analysis and Validation

### Configuration Validation Script
```bash
#!/bin/bash
# validate-configuration.sh

RELEASE_NAME=$1
CHART_NAME=$2
VALUES_FILE=$3

echo "ğŸ” Validating configuration for $RELEASE_NAME"

# Perform dry-run and capture output
DRY_RUN_OUTPUT=$(helm upgrade $RELEASE_NAME $CHART_NAME \
  -f $VALUES_FILE \
  --dry-run \
  --debug 2>&1)

# Check for common issues
echo "$DRY_RUN_OUTPUT" | grep -i error && {
  echo "âŒ Errors found in configuration"
  exit 1
}

# Validate required resources
echo "$DRY_RUN_OUTPUT" | grep -q "kind: Deployment" || {
  echo "âš ï¸  No Deployment found"
}

echo "$DRY_RUN_OUTPUT" | grep -q "kind: Service" || {
  echo "âš ï¸  No Service found"
}

# Check resource limits
if echo "$DRY_RUN_OUTPUT" | grep -q "resources:"; then
  echo "âœ… Resource limits configured"
else
  echo "âš ï¸  No resource limits found"
fi

# Check security context
if echo "$DRY_RUN_OUTPUT" | grep -q "securityContext:"; then
  echo "âœ… Security context configured"
else
  echo "âš ï¸  No security context found"
fi

echo "âœ… Configuration validation complete"
```

### Resource Requirement Analysis
```bash
#!/bin/bash
# analyze-resources.sh

RELEASE_NAME=$1
VALUES_FILE=$2

echo "ğŸ“Š Analyzing resource requirements"

DRY_RUN_OUTPUT=$(helm upgrade $RELEASE_NAME bitnami/nginx \
  -f $VALUES_FILE \
  --dry-run \
  --debug 2>/dev/null)

# Extract CPU requests
CPU_REQUESTS=$(echo "$DRY_RUN_OUTPUT" | \
  grep -A 5 "requests:" | \
  grep "cpu:" | \
  awk '{print $2}' | \
  sed 's/"//g')

# Extract memory requests
MEMORY_REQUESTS=$(echo "$DRY_RUN_OUTPUT" | \
  grep -A 5 "requests:" | \
  grep "memory:" | \
  awk '{print $2}' | \
  sed 's/"//g')

# Extract replica count
REPLICAS=$(echo "$DRY_RUN_OUTPUT" | \
  grep "replicas:" | \
  awk '{print $2}')

echo "Replica Count: $REPLICAS"
echo "CPU Request per pod: $CPU_REQUESTS"
echo "Memory Request per pod: $MEMORY_REQUESTS"

# Calculate total resources (simplified)
if [[ $CPU_REQUESTS =~ ([0-9]+)m ]]; then
  TOTAL_CPU=$((${BASH_REMATCH[1]} * $REPLICAS))
  echo "Total CPU requests: ${TOTAL_CPU}m"
fi
```

## ğŸ”„ CI/CD Integration with Dry-Runs

### GitLab CI Pipeline Example
```yaml
# .gitlab-ci.yml
validate-helm-changes:
  stage: validate
  image: alpine/helm:latest
  script:
    - helm repo add bitnami https://charts.bitnami.com/bitnami
    - helm repo update
    - |
      for env in dev staging prod; do
        echo "Validating $env configuration..."
        helm upgrade my-app bitnami/nginx \
          -f values/common.yaml \
          -f values/${env}.yaml \
          --dry-run \
          --debug > dry-run-${env}.yaml
        
        # Check for errors in dry-run output
        if grep -i error dry-run-${env}.yaml; then
          echo "âŒ Validation failed for $env"
          exit 1
        fi
        echo "âœ… $env validation passed"
      done
  artifacts:
    paths:
      - dry-run-*.yaml
    expire_in: 1 day
```

### GitHub Actions Example
```yaml
# .github/workflows/helm-validate.yml
name: Helm Validation
on: [pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Setup Helm
        uses: azure/setup-helm@v1
        with:
          version: '3.12.0'
      
      - name: Add Helm repositories
        run: |
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update
      
      - name: Validate Helm charts
        run: |
          ./scripts/validate-all-environments.sh
      
      - name: Upload dry-run artifacts
        uses: actions/upload-artifact@v2
        with:
          name: helm-dry-run-outputs
          path: dry-run-*.yaml
```

## ğŸ›¡ï¸ Pre-Deployment Safety Checks

### Comprehensive Validation Script
```bash
#!/bin/bash
# comprehensive-validation.sh

RELEASE_NAME=$1
CHART_NAME=$2
VALUES_FILE=$3
NAMESPACE=${4:-default}

echo "ğŸ”’ Comprehensive pre-deployment validation"

# 1. Syntax and template validation
echo "1ï¸âƒ£ Testing template syntax..."
if ! helm template $RELEASE_NAME $CHART_NAME -f $VALUES_FILE > /dev/null 2>&1; then
  echo "âŒ Template syntax error"
  helm template $RELEASE_NAME $CHART_NAME -f $VALUES_FILE
  exit 1
fi

# 2. Dry-run validation
echo "2ï¸âƒ£ Performing dry-run..."
DRY_RUN_OUTPUT=$(helm upgrade $RELEASE_NAME $CHART_NAME \
  -f $VALUES_FILE \
  --namespace $NAMESPACE \
  --dry-run \
  --debug 2>&1)

if echo "$DRY_RUN_OUTPUT" | grep -i error; then
  echo "âŒ Dry-run validation failed"
  exit 1
fi

# 3. Resource validation
echo "3ï¸âƒ£ Validating resources..."
echo "$DRY_RUN_OUTPUT" > temp-dry-run.yaml

# Check for required Kubernetes API versions
kubectl api-versions > available-apis.txt
while IFS= read -r line; do
  if [[ $line =~ apiVersion:[:space:]*(.*) ]]; then
    API_VERSION=$(echo "${BASH_REMATCH[1]}" | tr -d '"' | tr -d "'")
    if ! grep -q "^$API_VERSION$" available-apis.txt; then
      echo "âš ï¸  Warning: API version $API_VERSION may not be available"
    fi
  fi
done < temp-dry-run.yaml

# 4. Security validation
echo "4ï¸âƒ£ Security validation..."
if ! echo "$DRY_RUN_OUTPUT" | grep -q "runAsNonRoot: true"; then
  echo "âš ï¸  Security warning: Not running as non-root user"
fi

if ! echo "$DRY_RUN_OUTPUT" | grep -q "readOnlyRootFilesystem: true"; then
  echo "âš ï¸  Security warning: Root filesystem is writable"
fi

# 5. Resource limits validation
echo "5ï¸âƒ£ Resource limits validation..."
if ! echo "$DRY_RUN_OUTPUT" | grep -q "limits:"; then
  echo "âš ï¸  Warning: No resource limits defined"
fi

echo "âœ… Validation complete"
rm -f temp-dry-run.yaml available-apis.txt
```

## ğŸ“‹ Common Dry-Run Use Cases

### Configuration Testing
```bash
# Test different configuration scenarios
test_scenarios=(
  "minimal-config.yaml"
  "high-availability.yaml"
  "resource-constrained.yaml"
  "security-hardened.yaml"
)

for scenario in "${test_scenarios[@]}"; do
  echo "Testing scenario: $scenario"
  if helm upgrade my-app bitnami/nginx \
     -f "scenarios/$scenario" \
     --dry-run > /dev/null 2>&1; then
    echo "âœ… $scenario - Valid"
  else
    echo "âŒ $scenario - Invalid"
  fi
done
```

### Version Compatibility Testing
```bash
#!/bin/bash
# version-compatibility-test.sh

CHART_VERSIONS=("15.0.0" "15.1.0" "15.2.0")
VALUES_FILE="production-values.yaml"

for version in "${CHART_VERSIONS[@]}"; do
  echo "Testing chart version: $version"
  
  if helm upgrade my-app bitnami/nginx \
     --version $version \
     -f $VALUES_FILE \
     --dry-run > "dry-run-v${version}.yaml" 2>&1; then
    echo "âœ… Version $version - Compatible"
  else
    echo "âŒ Version $version - Incompatible"
    grep -i error "dry-run-v${version}.yaml"
  fi
done
```

## ğŸ“ Practice Exercises

### Exercise 1: Basic Dry-Run Validation
1. **Create values file**: Define custom configuration
2. **Perform dry-run**: Test upgrade without applying
3. **Analyze output**: Understand the generated manifests
4. **Identify changes**: Compare with current deployment

### Exercise 2: Error Detection
1. **Create invalid configuration**: Intentionally break values
2. **Run dry-run**: See how errors are reported
3. **Fix issues**: Correct the configuration problems
4. **Validate fixes**: Confirm dry-run passes

### Exercise 3: Multi-Environment Validation
1. **Create environment files**: Different configs for dev/prod
2. **Validate all environments**: Use dry-run for each
3. **Compare outputs**: Understand environment differences
4. **Automate validation**: Create script to test all environments

### Exercise 4: CI/CD Integration
1. **Set up validation pipeline**: Integrate dry-run in CI/CD
2. **Test pull requests**: Validate changes automatically
3. **Generate artifacts**: Save dry-run outputs for review
4. **Add quality gates**: Block invalid configurations

## ğŸ“ Dry-Run Best Practices

### Always Use Dry-Run When:
- âœ… Testing new configurations
- âœ… Upgrading to new chart versions
- âœ… Deploying to production
- âœ… Making significant changes
- âœ… Validating CI/CD pipelines

### Dry-Run Analysis Checklist:
- âœ… Check for syntax errors
- âœ… Validate resource requirements
- âœ… Review security configurations
- âœ… Verify API version compatibility
- âœ… Check for breaking changes

### Output Management:
- âœ… Save dry-run outputs for review
- âœ… Compare outputs between versions
- âœ… Archive outputs for audit trail
- âœ… Share outputs with team for review

### Integration Tips:
- âœ… Integrate with CI/CD pipelines
- âœ… Use in pull request validation
- âœ… Combine with linting tools
- âœ… Automate common validation checks

## ğŸ”„ Dry-Run Limitations

### What Dry-Run Cannot Test:
- âŒ Runtime behavior
- âŒ Application startup issues
- âŒ Resource availability in cluster
- âŒ Network connectivity
- âŒ Persistent volume availability
- âŒ External service dependencies

### Additional Testing Needed:
- ğŸ§ª Staging environment testing
- ğŸ§ª Integration testing
- ğŸ§ª Load testing
- ğŸ§ª Monitoring and alerting validation

## â¡ï¸ Next Steps
Now that you understand dry-run validation, proceed to [8. Practice.md](8.%20Practice.md) for hands-on exercises combining all Helm concepts: deployment, upgrades, rollbacks, and validation workflows.