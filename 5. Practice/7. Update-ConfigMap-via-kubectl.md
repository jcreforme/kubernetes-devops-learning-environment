# Practice: Update ConfigMap and Verify Application Picks Up Changes

## Objective
Learn how to update a ConfigMap using kubectl and ensure running pods pick up the changes.

## Prerequisites
- Running deployment: `my-app-my-custom-app`
- Existing ConfigMap: `my-app-my-custom-app-config`

---

## Step 1: View Current ConfigMap

```powershell
# View the entire ConfigMap
kubectl get configmap my-app-my-custom-app-config -o yaml

# View just the app-config.json data
kubectl get configmap my-app-my-custom-app-config -o jsonpath='{.data.app-config\.json}' | ConvertFrom-Json
```

**Expected Output:**
```json
{
  "appName": "my-app-my-custom-app",
  "environment": "production",
  "replicaCount": "1",
  "version": "1.16.0",
  "namespace": "default"
}
```

---

## Step 2: Edit the ConfigMap

```powershell
kubectl edit configmap my-app-my-custom-app-config
```

**What to change:**
1. Find `"environment": "production"`
2. Change it to `"environment": "staging"`
3. Find `"replicaCount": "1"`
4. Change it to `"replicaCount": "3"`
5. Save and close the file

**Tip:** The editor opens in VS Code or Notepad depending on your `KUBE_EDITOR` setting.

---

## Step 3: Verify ConfigMap Updated

```powershell
kubectl get configmap my-app-my-custom-app-config -o jsonpath='{.data.app-config\.json}'
```

**Expected Output:**
```json
{
  "appName": "my-app-my-custom-app",
  "environment": "staging",
  "replicaCount": "3",
  ...
}
```

✅ ConfigMap is updated in the cluster immediately.

---

## Step 4: Check if Pods See the Change (Before Restart)

**Important:** How the pod accesses the ConfigMap matters:

### A. If ConfigMap is Mounted as Volume
```powershell
# Check file in pod (if mounted at /etc/config)
kubectl exec deployment/my-app-my-custom-app -- cat /etc/config/app-config.json
```

**Result:** File updates after ~60-90 seconds, BUT the application needs to reload it.

### B. If ConfigMap is Used as Environment Variables
```powershell
# Check environment variable
kubectl exec deployment/my-app-my-custom-app -- env | Select-String ENVIRONMENT
```

**Result:** ❌ No change! Environment variables are set at pod startup only.

### C. Our Current Setup
```powershell
# Our ConfigMap isn't mounted or used as env vars - it's just stored data
kubectl exec deployment/my-app-my-custom-app -- cat /etc/config/app-config.json
```

**Result:** `cat: /etc/config/app-config.json: No such file or directory`

---

## Step 5: Restart Pods to Pick Up Changes

Even though our ConfigMap isn't directly used by nginx, let's practice the restart workflow:

```powershell
# Trigger a rolling restart
kubectl rollout restart deployment my-app-my-custom-app

# Watch the rollout
kubectl rollout status deployment my-app-my-custom-app

# Verify new pods are running
kubectl get pods -l app.kubernetes.io/name=my-custom-app
```

**Expected Output:**
```
NAME                                    READY   STATUS    RESTARTS   AGE
my-app-my-custom-app-xxxxxxxxxx-xxxxx   1/1     Running   0          30s
my-app-my-custom-app-xxxxxxxxxx-xxxxx   1/1     Running   0          33s
my-app-my-custom-app-xxxxxxxxxx-xxxxx   1/1     Running   0          36s
```

All pods should have fresh AGE (less than 1 minute).

---

## Step 6: Verify the Change Persists

```powershell
# Check ConfigMap still has your changes
kubectl get configmap my-app-my-custom-app-config -o jsonpath='{.data.app-config\.json}' | ConvertFrom-Json

# Check ConfigMap version/resourceVersion (should have changed)
kubectl get configmap my-app-my-custom-app-config -o jsonpath='{.metadata.resourceVersion}'
```

---

## Step 7: (Optional) Mount ConfigMap to Actually Use It

To make pods actually read the ConfigMap, you'd need to modify the Deployment:

```yaml
# In deployment.yaml template
volumeMounts:
  - name: config
    mountPath: /etc/config
volumes:
  - name: config
    configMap:
      name: my-app-my-custom-app-config
```

Then:
```powershell
# After helm upgrade
kubectl exec deployment/my-app-my-custom-app -- cat /etc/config/app-config.json
```

Would show the ConfigMap content inside the pod.

---

## Important Warnings ⚠️

### 1. kubectl edit Changes Are Not Tracked
- Changes made with `kubectl edit` exist only in the cluster
- Not in Git, not in your values files
- Next `helm upgrade` will **overwrite** your changes

### 2. When to Restart Pods
- **Environment Variables:** Always need restart
- **Volume Mounts:** File updates automatically, but app may need reload
- **No Mount/Env:** ConfigMap change doesn't affect running pods

### 3. Best Practice
For production Helm-managed apps:
```powershell
# ❌ Don't do this
kubectl edit configmap my-config

# ✅ Do this instead
# 1. Edit templates/configmap.yaml or values.yaml
# 2. helm upgrade my-app ./my-custom-app -f my-custom-values.yaml
# 3. Commit to Git
```

---

## Verification Checklist

- [ ] ConfigMap shows updated values via `kubectl get configmap`
- [ ] Pods were restarted (new AGE)
- [ ] Understand the difference between ConfigMap data and Pod labels
- [ ] Know when pods need restart (env vars vs volume mounts)
- [ ] Understand `kubectl edit` changes will be overwritten by Helm

---

## Common Issues

**Issue:** Pods don't see the change after ConfigMap edit
- **Cause:** Using environment variables (set at startup only)
- **Solution:** Restart pods with `kubectl rollout restart`

**Issue:** Changes disappeared after `helm upgrade`
- **Cause:** Helm overwrites manual kubectl changes
- **Solution:** Edit values.yaml and use `helm upgrade` instead

**Issue:** Application shows old config after pod restart
- **Cause:** Application caches config or doesn't reload
- **Solution:** Check application logs, may need app-level reload

---

## Summary

1. ✅ `kubectl edit configmap` - Changes ConfigMap in cluster
2. ✅ Verify with `kubectl get configmap`
3. ✅ `kubectl rollout restart deployment` - Recreates pods
4. ⚠️ Application must be designed to read ConfigMap (volume mount or env vars)
5. ⚠️ `kubectl edit` changes are temporary for Helm-managed resources

**Best Practice:** Use `helm upgrade` for persistent, tracked, repeatable changes.
