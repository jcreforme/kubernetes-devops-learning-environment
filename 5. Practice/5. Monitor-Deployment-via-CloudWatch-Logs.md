# 5. Monitor Deployment via CloudWatch Logs

## üéØ Learning Objectives
- [ ] Set up CloudWatch logging for Kubernetes deployments
- [ ] Configure log aggregation and parsing
- [ ] Create CloudWatch Insights queries for troubleshooting
- [ ] Implement log-based monitoring and alerting
- [ ] Analyze application and infrastructure logs

## üìã Prerequisites
- AWS EKS cluster or EC2-based Kubernetes with CloudWatch agent
- Application deployed from previous exercises
- AWS CLI configured with appropriate permissions
- kubectl access to the cluster

## üõ†Ô∏è Step 1: Setup CloudWatch Container Insights

### Enable Container Insights for EKS
```bash
# Install CloudWatch Container Insights
curl -s https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluentd-quickstart.yaml | sed "s/{{cluster_name}}/my-cluster/;s/{{region_name}}/us-west-2/" | kubectl apply -f -

# Verify installation
kubectl get pods -n amazon-cloudwatch

# Check DaemonSet status
kubectl get daemonset -n amazon-cloudwatch
```

### Configure FluentBit for Enhanced Logging
```yaml
# fluent-bit-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: amazon-cloudwatch
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         5
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    @INCLUDE application-log.conf
    @INCLUDE dataplane-log.conf
    @INCLUDE host-log.conf

  application-log.conf: |
    [INPUT]
        Name              tail
        Tag               application.*
        Exclude_Path      /var/log/containers/cloudwatch-agent*, /var/log/containers/fluent-bit*, /var/log/containers/aws-node*, /var/log/containers/kube-proxy*
        Path              /var/log/containers/*.log
        Parser            cri
        DB                /var/fluent-bit/state/flb_container.db
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
        Refresh_Interval  10

    [FILTER]
        Name                kubernetes
        Match               application.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Merge_Log           On
        K8S-Logging.Parser  On
        K8S-Logging.Exclude Off
        Annotations         Off
        Labels              On

    # Enhanced parsing for our application logs
    [FILTER]
        Name                modify
        Match               application.*my-app*
        Add                 app_name my-sample-app
        Add                 log_source application

    [OUTPUT]
        Name                cloudwatch_logs
        Match               application.*
        region              us-west-2
        log_group_name      /aws/containerinsights/my-cluster/application
        log_stream_prefix   my-app-
        auto_create_group   true

  parsers.conf: |
    [PARSER]
        Name        cri
        Format      regex
        Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z

    [PARSER]
        Name        json
        Format      json
        Time_Key    timestamp
        Time_Format %Y-%m-%dT%H:%M:%S.%L

    [PARSER]
        Name        application
        Format      regex
        Regex       ^\[(?<timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z)\] (?<level>\w+): (?<message>.*)$
        Time_Key    timestamp
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
```

### Apply FluentBit Configuration
```bash
# Apply the enhanced FluentBit configuration
kubectl apply -f fluent-bit-config.yaml

# Restart FluentBit to pick up new configuration
kubectl rollout restart daemonset/fluent-bit -n amazon-cloudwatch

# Verify configuration
kubectl logs -n amazon-cloudwatch -l k8s-app=fluent-bit --tail=50
```

## üìä Step 2: Configure Application Logging

### Update Application to Generate Structured Logs
```yaml
# app-logging-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-logging-config
  namespace: development-kustomize
data:
  log4j2.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <Configuration status="WARN">
        <Appenders>
            <Console name="Console" target="SYSTEM_OUT">
                <PatternLayout pattern="[%d{yyyy-MM-dd'T'HH:mm:ss.SSSZ}] %level: %msg%n"/>
            </Console>
            <Console name="JsonConsole" target="SYSTEM_OUT">
                <JsonLayout compact="true" eventEol="true">
                    <KeyValuePair key="timestamp" value="$${date:yyyy-MM-dd'T'HH:mm:ss.SSSZ}"/>
                    <KeyValuePair key="level" value="$${level}"/>
                    <KeyValuePair key="logger" value="$${logger}"/>
                    <KeyValuePair key="message" value="$${message}"/>
                    <KeyValuePair key="thread" value="$${thread}"/>
                    <KeyValuePair key="app_name" value="my-sample-app"/>
                    <KeyValuePair key="environment" value="$${env:ENVIRONMENT:-unknown}"/>
                </JsonLayout>
            </Console>
        </Appenders>
        <Loggers>
            <Logger name="com.myapp" level="DEBUG" additivity="false">
                <AppenderRef ref="JsonConsole"/>
            </Logger>
            <Root level="INFO">
                <AppenderRef ref="Console"/>
            </Root>
        </Loggers>
    </Configuration>

  application.properties: |
    # Application logging configuration
    logging.level.com.myapp=DEBUG
    logging.level.org.springframework=INFO
    logging.pattern.console=[%d{yyyy-MM-dd'T'HH:mm:ss.SSSZ}] %level: %logger{36} - %msg%n
    
    # Custom application metrics logging
    app.metrics.enabled=true
    app.metrics.interval=30
    app.audit.enabled=true

---
# Apply logging configuration to deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dev-deployment-kustomize
  namespace: development-kustomize
spec:
  template:
    spec:
      containers:
      - name: my-app
        env:
        - name: LOGGING_CONFIG
          value: /config/log4j2.xml
        - name: STRUCTURED_LOGGING
          value: "true"
        volumeMounts:
        - name: logging-config
          mountPath: /config
      volumes:
      - name: logging-config
        configMap:
          name: app-logging-config
```

### Generate Test Logs
```bash
# Apply logging configuration
kubectl apply -f app-logging-config.yaml

# Restart deployment to pick up logging config
kubectl rollout restart deployment/dev-deployment-kustomize -n development-kustomize

# Generate test logs
kubectl exec -n development-kustomize deployment/dev-deployment-kustomize -- sh -c '
for i in $(seq 1 100); do
  echo "[$(date -Iseconds)] INFO: Test log message $i - User action performed"
  echo "[$(date -Iseconds)] DEBUG: Processing request $i with parameters"
  echo "[$(date -Iseconds)] WARN: Rate limit approaching for user session"
  if [ $((i % 20)) -eq 0 ]; then
    echo "[$(date -Iseconds)] ERROR: Simulated error condition for testing"
  fi
  sleep 2
done
'

# Check logs are being generated
kubectl logs -n development-kustomize deployment/dev-deployment-kustomize --tail=20
```

## üîç Step 3: Create CloudWatch Log Groups and Streams

### Set Up Custom Log Groups
```bash
# Create custom log groups for different log types
aws logs create-log-group \
    --log-group-name /aws/containerinsights/my-cluster/application \
    --region us-west-2

aws logs create-log-group \
    --log-group-name /aws/containerinsights/my-cluster/application/errors \
    --region us-west-2

aws logs create-log-group \
    --log-group-name /aws/containerinsights/my-cluster/application/audit \
    --region us-west-2

# Set retention policies
aws logs put-retention-policy \
    --log-group-name /aws/containerinsights/my-cluster/application \
    --retention-in-days 30 \
    --region us-west-2

aws logs put-retention-policy \
    --log-group-name /aws/containerinsights/my-cluster/application/errors \
    --retention-in-days 90 \
    --region us-west-2
```

### Configure Log Routing with Fluent Bit
```yaml
# enhanced-fluent-bit.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: amazon-cloudwatch
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         5
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    @INCLUDE application-log.conf

  application-log.conf: |
    [INPUT]
        Name              tail
        Tag               kube.*
        Path              /var/log/containers/*my-app*.log
        Parser            cri
        DB                /var/fluent-bit/state/flb_application.db
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
        Refresh_Interval  10

    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Merge_Log           On

    # Parse application logs
    [FILTER]
        Name                parser
        Match               kube.*my-app*
        Key_Name            log
        Parser              application
        Reserve_Data        On

    # Route ERROR logs to separate log group
    [OUTPUT]
        Name                cloudwatch_logs
        Match               kube.*my-app*
        region              us-west-2
        log_group_name      /aws/containerinsights/my-cluster/application/errors
        log_stream_prefix   error-
        log_key             message
        auto_create_group   true
        log_format          json

    # Route all application logs
    [OUTPUT]
        Name                cloudwatch_logs
        Match               kube.*my-app*
        region              us-west-2
        log_group_name      /aws/containerinsights/my-cluster/application
        log_stream_prefix   app-
        auto_create_group   true
        log_format          json

  parsers.conf: |
    [PARSER]
        Name        cri
        Format      regex
        Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z

    [PARSER]
        Name        application
        Format      regex
        Regex       ^\[(?<timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z)\] (?<level>\w+): (?<message>.*)$
        Time_Key    timestamp
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
```

## üìà Step 4: CloudWatch Insights Queries

### Basic Application Monitoring Queries
```bash
# Create CloudWatch Insights queries file
cat << 'EOF' > cloudwatch-queries.txt
# 1. Error Rate Analysis
fields @timestamp, level, message, kubernetes.pod_name
| filter level = "ERROR"
| stats count() as error_count by bin(5m)
| sort @timestamp desc

# 2. Application Performance - Response Times
fields @timestamp, message, kubernetes.pod_name
| filter message like /response_time/
| parse message "response_time=* status=*" as response_time, status
| stats avg(response_time), max(response_time), min(response_time) by bin(5m)

# 3. Pod Restart Analysis
fields @timestamp, kubernetes.pod_name, message
| filter message like /Started/
| stats count() as restart_count by kubernetes.pod_name
| sort restart_count desc

# 4. Memory Usage Patterns
fields @timestamp, kubernetes.pod_name, message
| filter message like /memory/
| parse message "memory_usage=* memory_limit=*" as usage, limit
| stats avg(usage/limit*100) as avg_memory_percent by kubernetes.pod_name, bin(10m)

# 5. Database Connection Analysis
fields @timestamp, message, level
| filter message like /database/ or message like /connection/
| stats count() as connection_events by level, bin(5m)
| sort @timestamp desc

# 6. User Activity Monitoring
fields @timestamp, message, kubernetes.namespace
| filter message like /user_action/
| parse message "user_id=* action=*" as user_id, action
| stats count() as action_count by action, bin(1h)
| sort action_count desc

# 7. API Endpoint Usage
fields @timestamp, message
| filter message like /GET|POST|PUT|DELETE/
| parse message "* * HTTP/*" as method, endpoint, version
| stats count() as request_count by endpoint, method
| sort request_count desc
| limit 20

# 8. Error Pattern Analysis
fields @timestamp, level, message, kubernetes.pod_name
| filter level = "ERROR"
| stats count() as error_count by message
| sort error_count desc
| limit 10

# 9. Slow Query Detection
fields @timestamp, message
| filter message like /query_time/
| parse message "query_time=* query=*" as query_time, query
| filter query_time > 1000
| stats count() as slow_queries, avg(query_time) as avg_time by query
| sort avg_time desc

# 10. Health Check Monitoring
fields @timestamp, message, kubernetes.pod_name
| filter message like /health|ready/
| parse message "endpoint=* status=* response_time=*" as endpoint, status, response_time
| stats count() as checks, avg(response_time) as avg_response by status, bin(5m)
EOF

echo "üìä CloudWatch Insights queries created in cloudwatch-queries.txt"
```

### Execute Queries Programmatically
```bash
# Create script to run CloudWatch Insights queries
cat << 'EOF' > run-insights-query.sh
#!/bin/bash

LOG_GROUP=${1:-"/aws/containerinsights/my-cluster/application"}
QUERY=${2:-"fields @timestamp, @message | limit 20"}
START_TIME=${3:-"-1h"}

echo "üîç Running CloudWatch Insights query..."
echo "Log Group: $LOG_GROUP"
echo "Query: $QUERY"

# Convert relative time to epoch
if [[ $START_TIME == -* ]]; then
    START_EPOCH=$(date -d "$START_TIME" +%s)
else
    START_EPOCH=$START_TIME
fi

END_EPOCH=$(date +%s)

# Start query
QUERY_ID=$(aws logs start-query \
    --log-group-name "$LOG_GROUP" \
    --start-time "$START_EPOCH" \
    --end-time "$END_EPOCH" \
    --query-string "$QUERY" \
    --region us-west-2 \
    --query 'queryId' \
    --output text)

echo "Query ID: $QUERY_ID"
echo "Waiting for results..."

# Poll for results
while true; do
    STATUS=$(aws logs get-query-results \
        --query-id "$QUERY_ID" \
        --region us-west-2 \
        --query 'status' \
        --output text)
    
    if [ "$STATUS" = "Complete" ]; then
        echo "‚úÖ Query completed. Results:"
        aws logs get-query-results \
            --query-id "$QUERY_ID" \
            --region us-west-2 \
            --query 'results' \
            --output table
        break
    elif [ "$STATUS" = "Failed" ]; then
        echo "‚ùå Query failed"
        break
    else
        echo "Status: $STATUS - waiting..."
        sleep 2
    fi
done
EOF

chmod +x run-insights-query.sh

# Example usage
./run-insights-query.sh "/aws/containerinsights/my-cluster/application" "fields @timestamp, level, message | filter level = 'ERROR' | limit 10"
```

## üö® Step 5: Set Up CloudWatch Alarms

### Create Log-Based Alarms
```bash
# Create metric filters and alarms
cat << 'EOF' > create-cloudwatch-alarms.sh
#!/bin/bash

LOG_GROUP="/aws/containerinsights/my-cluster/application"
REGION="us-west-2"

echo "üö® Creating CloudWatch metric filters and alarms..."

# 1. Error Rate Metric Filter
aws logs put-metric-filter \
    --log-group-name "$LOG_GROUP" \
    --filter-name "ApplicationErrors" \
    --filter-pattern "[timestamp, level=\"ERROR\", ...]" \
    --metric-transformations \
        metricName=ApplicationErrorCount,\
        metricNamespace=MyApp/Logs,\
        metricValue=1,\
        defaultValue=0 \
    --region "$REGION"

# 2. High Memory Usage Metric Filter
aws logs put-metric-filter \
    --log-group-name "$LOG_GROUP" \
    --filter-name "HighMemoryUsage" \
    --filter-pattern "[timestamp, level, message=\"*memory_usage*\"]" \
    --metric-transformations \
        metricName=HighMemoryEvents,\
        metricNamespace=MyApp/Logs,\
        metricValue=1 \
    --region "$REGION"

# 3. Database Connection Errors
aws logs put-metric-filter \
    --log-group-name "$LOG_GROUP" \
    --filter-name "DatabaseErrors" \
    --filter-pattern "[timestamp, level=\"ERROR\", message=\"*database*\" || message=\"*connection*\"]" \
    --metric-transformations \
        metricName=DatabaseErrorCount,\
        metricNamespace=MyApp/Logs,\
        metricValue=1 \
    --region "$REGION"

# Create SNS topic for alerts
SNS_TOPIC_ARN=$(aws sns create-topic \
    --name my-app-alerts \
    --region "$REGION" \
    --query 'TopicArn' \
    --output text)

echo "SNS Topic ARN: $SNS_TOPIC_ARN"

# Subscribe email to SNS topic
read -p "Enter email for alerts: " EMAIL_ADDRESS
aws sns subscribe \
    --topic-arn "$SNS_TOPIC_ARN" \
    --protocol email \
    --notification-endpoint "$EMAIL_ADDRESS" \
    --region "$REGION"

# 1. Error Rate Alarm
aws cloudwatch put-metric-alarm \
    --alarm-name "MyApp-HighErrorRate" \
    --alarm-description "Alert when error rate is high" \
    --metric-name ApplicationErrorCount \
    --namespace MyApp/Logs \
    --statistic Sum \
    --period 300 \
    --threshold 5 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 2 \
    --alarm-actions "$SNS_TOPIC_ARN" \
    --region "$REGION"

# 2. Database Connection Alarm
aws cloudwatch put-metric-alarm \
    --alarm-name "MyApp-DatabaseConnectionErrors" \
    --alarm-description "Alert when database connection errors occur" \
    --metric-name DatabaseErrorCount \
    --namespace MyApp/Logs \
    --statistic Sum \
    --period 300 \
    --threshold 1 \
    --comparison-operator GreaterThanThreshold \
    --evaluation-periods 1 \
    --alarm-actions "$SNS_TOPIC_ARN" \
    --region "$REGION"

# 3. No Data Alarm (Application Not Logging)
aws cloudwatch put-metric-alarm \
    --alarm-name "MyApp-NoLogs" \
    --alarm-description "Alert when application stops logging" \
    --metric-name ApplicationErrorCount \
    --namespace MyApp/Logs \
    --statistic Sum \
    --period 600 \
    --threshold 1 \
    --comparison-operator LessThanThreshold \
    --evaluation-periods 3 \
    --treat-missing-data breaching \
    --alarm-actions "$SNS_TOPIC_ARN" \
    --region "$REGION"

echo "‚úÖ CloudWatch alarms created successfully"
EOF

chmod +x create-cloudwatch-alarms.sh
./create-cloudwatch-alarms.sh
```

### Test Alarm Triggers
```bash
# Generate error logs to trigger alarms
kubectl exec -n development-kustomize deployment/dev-deployment-kustomize -- sh -c '
echo "[$(date -Iseconds)] ERROR: Database connection failed - testing alarm"
echo "[$(date -Iseconds)] ERROR: Memory allocation error - testing alarm"
echo "[$(date -Iseconds)] ERROR: API timeout error - testing alarm"
echo "[$(date -Iseconds)] ERROR: Authentication failure - testing alarm"
echo "[$(date -Iseconds)] ERROR: Service unavailable - testing alarm"
echo "[$(date -Iseconds)] ERROR: Configuration error - testing alarm"
'

# Check alarm states
aws cloudwatch describe-alarms \
    --alarm-names "MyApp-HighErrorRate" "MyApp-DatabaseConnectionErrors" \
    --region us-west-2 \
    --query 'MetricAlarms[*].[AlarmName,StateValue,StateReason]' \
    --output table
```

## üìä Step 6: Create CloudWatch Dashboard

### Build Comprehensive Dashboard
```bash
# Create CloudWatch dashboard
cat << 'EOF' > create-dashboard.sh
#!/bin/bash

REGION="us-west-2"
CLUSTER_NAME="my-cluster"

# Create dashboard JSON
cat > dashboard.json << DASHBOARD_EOF
{
    "widgets": [
        {
            "type": "metric",
            "x": 0,
            "y": 0,
            "width": 12,
            "height": 6,
            "properties": {
                "metrics": [
                    [ "MyApp/Logs", "ApplicationErrorCount", { "stat": "Sum" } ],
                    [ ".", "DatabaseErrorCount", { "stat": "Sum" } ]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "$REGION",
                "title": "Application Error Rates",
                "yAxis": {
                    "left": {
                        "min": 0
                    }
                }
            }
        },
        {
            "type": "log",
            "x": 0,
            "y": 6,
            "width": 24,
            "height": 6,
            "properties": {
                "query": "SOURCE '/aws/containerinsights/$CLUSTER_NAME/application'\n| fields @timestamp, level, message, kubernetes.pod_name\n| filter level = \"ERROR\"\n| sort @timestamp desc\n| limit 50",
                "region": "$REGION",
                "title": "Recent Application Errors",
                "view": "table"
            }
        },
        {
            "type": "log",
            "x": 0,
            "y": 12,
            "width": 12,
            "height": 6,
            "properties": {
                "query": "SOURCE '/aws/containerinsights/$CLUSTER_NAME/application'\n| fields @timestamp, level\n| stats count() as log_count by level\n| sort log_count desc",
                "region": "$REGION",
                "title": "Log Level Distribution",
                "view": "pie"
            }
        },
        {
            "type": "log",
            "x": 12,
            "y": 12,
            "width": 12,
            "height": 6,
            "properties": {
                "query": "SOURCE '/aws/containerinsights/$CLUSTER_NAME/application'\n| fields @timestamp, kubernetes.pod_name\n| stats count() as log_count by kubernetes.pod_name\n| sort log_count desc",
                "region": "$REGION",
                "title": "Logs by Pod",
                "view": "bar"
            }
        },
        {
            "type": "log",
            "x": 0,
            "y": 18,
            "width": 24,
            "height": 6,
            "properties": {
                "query": "SOURCE '/aws/containerinsights/$CLUSTER_NAME/application'\n| fields @timestamp, message\n| filter message like /response_time/\n| parse message \"response_time=* status=*\" as response_time, status\n| stats avg(response_time) as avg_response_time by bin(5m)\n| sort @timestamp desc",
                "region": "$REGION",
                "title": "Average Response Time",
                "view": "line"
            }
        }
    ]
}
DASHBOARD_EOF

# Create the dashboard
aws cloudwatch put-dashboard \
    --dashboard-name "MyApp-Monitoring" \
    --dashboard-body file://dashboard.json \
    --region "$REGION"

echo "‚úÖ Dashboard created: https://$REGION.console.aws.amazon.com/cloudwatch/home?region=$REGION#dashboards:name=MyApp-Monitoring"

# Cleanup
rm dashboard.json
EOF

chmod +x create-dashboard.sh
./create-dashboard.sh
```

## üîß Step 7: Log Analysis and Troubleshooting

### Automated Log Analysis Script
```bash
# Create log analysis tool
cat << 'EOF' > analyze-logs.sh
#!/bin/bash

LOG_GROUP="/aws/containerinsights/my-cluster/application"
TIME_RANGE=${1:-"-1h"}
REGION="us-west-2"

echo "üìä Analyzing logs from $TIME_RANGE..."

# Function to run insights query and return results
run_query() {
    local query="$1"
    local title="$2"
    
    echo "üîç $title"
    echo "Query: $query"
    
    START_EPOCH=$(date -d "$TIME_RANGE" +%s)
    END_EPOCH=$(date +%s)
    
    QUERY_ID=$(aws logs start-query \
        --log-group-name "$LOG_GROUP" \
        --start-time "$START_EPOCH" \
        --end-time "$END_EPOCH" \
        --query-string "$query" \
        --region "$REGION" \
        --query 'queryId' \
        --output text)
    
    # Wait for completion
    while true; do
        STATUS=$(aws logs get-query-results \
            --query-id "$QUERY_ID" \
            --region "$REGION" \
            --query 'status' \
            --output text)
        
        if [ "$STATUS" = "Complete" ]; then
            aws logs get-query-results \
                --query-id "$QUERY_ID" \
                --region "$REGION" \
                --query 'results' \
                --output table
            break
        elif [ "$STATUS" = "Failed" ]; then
            echo "‚ùå Query failed"
            break
        else
            sleep 1
        fi
    done
    echo ""
}

# 1. Error Summary
run_query "fields @timestamp, level, message | filter level = 'ERROR' | stats count() as error_count by bin(10m) | sort @timestamp desc" "Error Rate Over Time"

# 2. Top Error Messages
run_query "fields @timestamp, message | filter level = 'ERROR' | stats count() as error_count by message | sort error_count desc | limit 5" "Top Error Messages"

# 3. Pod Health Summary
run_query "fields @timestamp, kubernetes.pod_name, level | stats count() as total_logs, sum(level='ERROR') as errors by kubernetes.pod_name | sort errors desc" "Pod Health Summary"

# 4. Response Time Analysis
run_query "fields @timestamp, message | filter message like /response_time/ | parse message 'response_time=* status=*' as response_time, status | stats avg(response_time) as avg_response, max(response_time) as max_response by status" "Response Time by Status"

# 5. Resource Usage Indicators
run_query "fields @timestamp, message | filter message like /memory|cpu/ | stats count() as resource_events by bin(15m) | sort @timestamp desc" "Resource Usage Events"

echo "‚úÖ Log analysis complete"
EOF

chmod +x analyze-logs.sh

# Run analysis
./analyze-logs.sh "-2h"
```

### Create Troubleshooting Playbook
```bash
# Create troubleshooting playbook
cat << 'EOF' > troubleshooting-playbook.md
# Application Troubleshooting Playbook

## üö® High Error Rate Alert

### Investigation Steps
1. Check recent error patterns:
```bash
./run-insights-query.sh "/aws/containerinsights/my-cluster/application" "fields @timestamp, level, message, kubernetes.pod_name | filter level = 'ERROR' | sort @timestamp desc | limit 20"
```

2. Identify affected pods:
```bash
kubectl get pods -n development-kustomize -l app.kubernetes.io/name=my-app
kubectl describe pods -n development-kustomize -l app.kubernetes.io/name=my-app
```

3. Check resource utilization:
```bash
kubectl top pods -n development-kustomize
```

## üîó Database Connection Issues

### Investigation Steps
1. Check database connection logs:
```bash
./run-insights-query.sh "/aws/containerinsights/my-cluster/application" "fields @timestamp, message | filter message like /database|connection/ | sort @timestamp desc"
```

2. Verify database service:
```bash
kubectl get svc -n development-kustomize
kubectl exec -n development-kustomize deployment/dev-deployment-kustomize -- nc -zv database-host 5432
```

## üêå Performance Issues

### Investigation Steps
1. Analyze response times:
```bash
./run-insights-query.sh "/aws/containerinsights/my-cluster/application" "fields @timestamp, message | filter message like /response_time/ | parse message 'response_time=*' as response_time | stats avg(response_time), max(response_time), min(response_time) by bin(5m)"
```

2. Check resource constraints:
```bash
kubectl describe nodes
kubectl top nodes
```

## üîÑ No Logs Alert

### Investigation Steps
1. Check if pods are running:
```bash
kubectl get pods -n development-kustomize -l app.kubernetes.io/name=my-app
```

2. Verify FluentBit is collecting logs:
```bash
kubectl logs -n amazon-cloudwatch -l k8s-app=fluent-bit
```

3. Check application stdout/stderr:
```bash
kubectl logs -n development-kustomize deployment/dev-deployment-kustomize
```
EOF

echo "üìö Troubleshooting playbook created"
```

## ‚úÖ Success Criteria

### ‚úÖ CloudWatch Monitoring Setup Checklist
- [ ] CloudWatch Container Insights enabled and running
- [ ] FluentBit configured for log aggregation
- [ ] Custom log groups created with retention policies
- [ ] Application generating structured logs
- [ ] CloudWatch Insights queries working
- [ ] Metric filters and alarms configured
- [ ] SNS notifications set up
- [ ] CloudWatch dashboard created
- [ ] Log analysis scripts functional
- [ ] Troubleshooting playbook prepared

### ‚úÖ Validation Commands
```bash
# All these should succeed:
kubectl get pods -n amazon-cloudwatch -l k8s-app=fluent-bit
aws logs describe-log-groups --region us-west-2 | grep my-cluster
aws cloudwatch describe-alarms --region us-west-2 | grep MyApp
kubectl logs -n development-kustomize deployment/dev-deployment-kustomize --tail=10
./run-insights-query.sh "/aws/containerinsights/my-cluster/application" "fields @message | limit 5"
```

## üß™ Testing and Validation

### Generate Load and Monitor
```bash
# Create load testing script
cat << 'EOF' > load-test-with-monitoring.sh
#!/bin/bash

NAMESPACE="development-kustomize"
DURATION=${1:-300}  # 5 minutes

echo "üöÄ Starting load test with monitoring for $DURATION seconds"

# Start monitoring logs in background
kubectl logs -f -n "$NAMESPACE" deployment/dev-deployment-kustomize > load-test-logs.txt &
LOG_PID=$!

# Generate load
kubectl run load-generator --rm -i --tty --restart=Never --image=busybox -- sh -c "
for i in \$(seq 1 1000); do
  echo 'Making request' \$i
  wget -qO- http://dev-service-kustomize.$NAMESPACE.svc.cluster.local:80/health
  if [ \$((i % 50)) -eq 0 ]; then
    echo 'Triggering error condition'
    wget -qO- http://dev-service-kustomize.$NAMESPACE.svc.cluster.local:80/error || true
  fi
  sleep 0.1
done
" &

LOAD_PID=$!

# Monitor CloudWatch metrics
echo "üìä Monitoring CloudWatch metrics..."
for i in $(seq 1 $((DURATION/30))); do
    echo "Check $i - $(date)"
    aws cloudwatch get-metric-statistics \
        --namespace MyApp/Logs \
        --metric-name ApplicationErrorCount \
        --dimensions \
        --statistics Sum \
        --start-time $(date -d '5 minutes ago' -u +%Y-%m-%dT%H:%M:%S) \
        --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
        --period 300 \
        --region us-west-2 \
        --query 'Datapoints[0].Sum'
    sleep 30
done

# Stop monitoring
kill $LOG_PID $LOAD_PID 2>/dev/null

echo "‚úÖ Load test completed. Check CloudWatch for metrics and alarms."
EOF

chmod +x load-test-with-monitoring.sh
./load-test-with-monitoring.sh 180
```

## üéì Key Takeaways

### What You've Learned
1. **CloudWatch Integration**: Setting up comprehensive logging for Kubernetes
2. **Log Aggregation**: Configuring FluentBit for structured log collection
3. **Insights Queries**: Creating powerful queries for log analysis and troubleshooting
4. **Monitoring Setup**: Implementing metric filters, alarms, and dashboards
5. **Operational Practices**: Building automated analysis and troubleshooting tools

### Monitoring Best Practices Implemented
- Structured logging with proper parsing
- Environment-specific log routing
- Automated alerting on error patterns
- Comprehensive dashboards for visibility
- Troubleshooting playbooks for common issues

This comprehensive monitoring setup provides full observability into your Kubernetes deployments with actionable insights and automated alerting.

## ‚û°Ô∏è Next Steps
Proceed to [6. Debug any issues using kubectl logs](6.%20Debug-Issues-Using-kubectl-Logs.md) to learn advanced debugging techniques using kubectl and integrate them with your CloudWatch monitoring setup.