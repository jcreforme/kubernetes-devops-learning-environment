# 2. Update ConfigMap via kubectl

## üéØ Learning Objectives
- [ ] Update ConfigMaps using kubectl commands
- [ ] Understand different ConfigMap update strategies
- [ ] Trigger application restarts to pick up configuration changes
- [ ] Monitor configuration changes and their effects
- [ ] Handle ConfigMap updates in production environments

## üìã Prerequisites
- Application deployed from previous exercise
- kubectl configured and connected to cluster
- Basic understanding of Kubernetes ConfigMaps
- Access to development and production namespaces

## üîß Step 1: Examine Current ConfigMap

### View Existing Configuration
```bash
# List ConfigMaps in development
kubectl get configmaps -n development

# View the current ConfigMap content
kubectl get configmap my-app-dev-config -n development -o yaml

# Get specific data from ConfigMap
kubectl get configmap my-app-dev-config -n development -o jsonpath='{.data.app\.properties}'
```

### Understand ConfigMap Structure
```yaml
# Current ConfigMap structure
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-dev-config
  namespace: development
data:
  app.properties: |
    app.name=my-sample-app
    app.environment=development
    log.level=debug
    database.host=postgres-dev.default.svc.cluster.local
    database.port=5432
    database.name=myapp_dev
    features.monitoring.enabled=true
    features.metrics.enabled=false
  nginx.conf: |
    # nginx configuration content...
```

## ‚ö° Step 2: Direct ConfigMap Updates

### Method 1: kubectl patch Command
```bash
# Update log level from debug to info
kubectl patch configmap my-app-dev-config -n development \
  --type merge \
  -p '{"data":{"app.properties":"app.name=my-sample-app\napp.environment=development\nlog.level=info\ndatabase.host=postgres-dev.default.svc.cluster.local\ndatabase.port=5432\ndatabase.name=myapp_dev\nfeatures.monitoring.enabled=true\nfeatures.metrics.enabled=false\n"}}'

# Verify the change
kubectl get configmap my-app-dev-config -n development -o jsonpath='{.data.app\.properties}' | grep log.level
```

### Method 2: kubectl edit Command
```bash
# Open ConfigMap in editor
kubectl edit configmap my-app-dev-config -n development

# In the editor, modify the configuration:
# Change log.level from info to warn
# Add new feature flag: features.cache.enabled=true
# Save and exit the editor

# Verify changes
kubectl get configmap my-app-dev-config -n development -o yaml
```

### Method 3: kubectl replace with File
```bash
# First, export current ConfigMap
kubectl get configmap my-app-dev-config -n development -o yaml > configmap-backup.yaml

# Create new ConfigMap file with desired changes
cat << EOF > updated-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-dev-config
  namespace: development
data:
  app.properties: |
    app.name=my-sample-app
    app.environment=development
    log.level=error
    database.host=postgres-dev.default.svc.cluster.local
    database.port=5432
    database.name=myapp_dev
    features.monitoring.enabled=true
    features.metrics.enabled=true
    features.cache.enabled=true
    features.debug.enabled=false
  nginx.conf: |
    server {
        listen 8080;
        server_name _;
        
        # Add new logging configuration
        access_log /var/log/nginx/access.log;
        error_log /var/log/nginx/error.log warn;
        
        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
            try_files \$uri \$uri/ /index.html;
        }
        
        location /health {
            access_log off;
            return 200 "healthy\\n";
            add_header Content-Type text/plain;
        }
        
        location /ready {
            access_log off;
            return 200 "ready\\n";
            add_header Content-Type text/plain;
        }
        
        # New endpoint for configuration info
        location /config {
            access_log off;
            return 200 "Config updated at $(date)\\n";
            add_header Content-Type text/plain;
        }
    }
EOF

# Apply the updated ConfigMap
kubectl replace -f updated-configmap.yaml

# Verify the replacement
kubectl get configmap my-app-dev-config -n development -o yaml
```

## üîÑ Step 3: Restart Application to Pick Up Changes

### Method 1: Rolling Restart
```bash
# Trigger a rolling restart of the deployment
kubectl rollout restart deployment/my-app-dev -n development

# Watch the rollout status
kubectl rollout status deployment/my-app-dev -n development --watch

# Verify new pods are running
kubectl get pods -n development -l app.kubernetes.io/name=my-app
```

### Method 2: Scale Down and Up
```bash
# Scale deployment to 0
kubectl scale deployment my-app-dev -n development --replicas=0

# Wait for pods to terminate
kubectl get pods -n development -l app.kubernetes.io/name=my-app --watch

# Scale back up
kubectl scale deployment my-app-dev -n development --replicas=1

# Verify pod is running with new configuration
kubectl get pods -n development -l app.kubernetes.io/name=my-app
```

### Method 3: Automatic Restart with Checksum
```bash
# Check if deployment has checksum annotation
kubectl get deployment my-app-dev -n development -o yaml | grep checksum

# The checksum should automatically trigger restart when ConfigMap changes
# If using Helm templates with checksum annotation, restart happens automatically
```

## üìä Step 4: Verify Configuration Changes

### Check Environment Variables in Pod
```bash
# Get pod name
POD_NAME=$(kubectl get pods -n development -l app.kubernetes.io/name=my-app -o jsonpath='{.items[0].metadata.name}')

# Check environment variables
kubectl exec -n development $POD_NAME -- env | grep -E "(LOG_LEVEL|APP_|DATABASE_)"

# Check mounted ConfigMap files
kubectl exec -n development $POD_NAME -- cat /etc/config/app.properties
kubectl exec -n development $POD_NAME -- cat /etc/config/nginx.conf
```

### Test Configuration Endpoints
```bash
# Port forward to application
kubectl port-forward -n development svc/my-app-dev 8080:80 &

# Test the new config endpoint
curl http://localhost:8080/config

# Check if log level change is reflected
curl http://localhost:8080/health

# Stop port forward
kill %1
```

### Monitor Application Logs
```bash
# Check recent logs for configuration changes
kubectl logs -n development -l app.kubernetes.io/name=my-app --tail=20

# Follow logs in real-time
kubectl logs -n development -l app.kubernetes.io/name=my-app -f

# Check for any configuration-related errors
kubectl logs -n development -l app.kubernetes.io/name=my-app | grep -i "config\|error\|warn"
```

## üè≠ Step 5: Production ConfigMap Update

### Safe Production Update Strategy
```bash
# 1. First, backup current production ConfigMap
kubectl get configmap my-app-prod-config -n production -o yaml > prod-configmap-backup.yaml

# 2. Create production-specific configuration
cat << EOF > prod-configmap-update.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-app-prod-config
  namespace: production
data:
  app.properties: |
    app.name=my-sample-app
    app.environment=production
    log.level=warn
    database.host=postgres-prod.database.svc.cluster.local
    database.port=5432
    database.name=myapp_prod
    features.monitoring.enabled=true
    features.metrics.enabled=true
    features.cache.enabled=true
    features.debug.enabled=false
    # Production-specific settings
    connection.pool.max=50
    connection.pool.timeout=30000
    security.audit.enabled=true
  nginx.conf: |
    server {
        listen 8080;
        server_name _;
        
        # Production logging
        access_log /var/log/nginx/access.log;
        error_log /var/log/nginx/error.log error;
        
        # Security headers
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        
        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
            try_files \$uri \$uri/ /index.html;
        }
        
        location /health {
            access_log off;
            return 200 "healthy\\n";
            add_header Content-Type text/plain;
        }
        
        location /ready {
            access_log off;
            return 200 "ready\\n";
            add_header Content-Type text/plain;
        }
    }
EOF

# 3. Apply the update during maintenance window
kubectl apply -f prod-configmap-update.yaml

# 4. Perform controlled restart of one replica at a time
kubectl patch deployment my-app-prod -n production -p '{"spec":{"template":{"metadata":{"annotations":{"kubectl.kubernetes.io/restartedAt":"'$(date +%Y-%m-%dT%H:%M:%S%z)'"}}}}}'

# 5. Watch the rolling update
kubectl rollout status deployment/my-app-prod -n production --watch

# 6. Verify all replicas are healthy
kubectl get pods -n production -l app.kubernetes.io/name=my-app
```

### Monitor Production Impact
```bash
# Check HPA scaling behavior
kubectl get hpa -n production

# Monitor resource utilization
kubectl top pods -n production -l app.kubernetes.io/name=my-app

# Check application availability
for i in {1..10}; do
  kubectl exec -n production deployment/my-app-prod -- curl -s http://localhost:8080/health
  echo " - Health check $i"
  sleep 2
done
```

## üõ†Ô∏è Step 6: Advanced ConfigMap Update Techniques

### Using ConfigMap from Literal Values
```bash
# Create ConfigMap from literals
kubectl create configmap app-runtime-config -n development \
  --from-literal=debug.enabled=true \
  --from-literal=cache.ttl=3600 \
  --from-literal=api.timeout=30s \
  --dry-run=client -o yaml > runtime-config.yaml

# Apply the new ConfigMap
kubectl apply -f runtime-config.yaml

# Update existing deployment to use the new ConfigMap
kubectl patch deployment my-app-dev -n development -p '{
  "spec": {
    "template": {
      "spec": {
        "containers": [{
          "name": "my-app",
          "envFrom": [{
            "configMapRef": {
              "name": "app-runtime-config"
            }
          }]
        }]
      }
    }
  }
}'
```

### Using ConfigMap from Files
```bash
# Create configuration files
echo "upstream backend {
    server backend1.example.com:8080;
    server backend2.example.com:8080;
}" > nginx-upstream.conf

echo "worker_processes auto;
worker_connections 1024;
keepalive_timeout 65;" > nginx-worker.conf

# Create ConfigMap from files
kubectl create configmap nginx-advanced-config -n development \
  --from-file=upstream.conf=nginx-upstream.conf \
  --from-file=worker.conf=nginx-worker.conf \
  --dry-run=client -o yaml > nginx-advanced.yaml

# Apply and mount in deployment
kubectl apply -f nginx-advanced.yaml
```

### Batch Update Multiple ConfigMaps
```bash
# Script to update multiple ConfigMaps
cat << 'EOF' > update-configs.sh
#!/bin/bash

NAMESPACE=${1:-development}
NEW_LOG_LEVEL=${2:-info}

echo "Updating ConfigMaps in namespace: $NAMESPACE"
echo "New log level: $NEW_LOG_LEVEL"

# List of ConfigMaps to update
CONFIGMAPS=("my-app-dev-config" "app-runtime-config")

for cm in "${CONFIGMAPS[@]}"; do
  if kubectl get configmap $cm -n $NAMESPACE &>/dev/null; then
    echo "Updating ConfigMap: $cm"
    
    # Get current data
    kubectl get configmap $cm -n $NAMESPACE -o yaml > temp-$cm.yaml
    
    # Update log level (simple sed replacement)
    sed -i "s/log\.level=.*/log.level=$NEW_LOG_LEVEL/" temp-$cm.yaml
    
    # Apply updated ConfigMap
    kubectl apply -f temp-$cm.yaml
    
    # Cleanup
    rm temp-$cm.yaml
    
    echo "‚úÖ Updated $cm"
  else
    echo "‚ùå ConfigMap $cm not found"
  fi
done

echo "üîÑ Restarting deployments to pick up changes..."
kubectl rollout restart deployment -l app.kubernetes.io/name=my-app -n $NAMESPACE
EOF

chmod +x update-configs.sh

# Run the batch update
./update-configs.sh development warn
```

## üß™ Step 7: Testing and Validation

### Validate ConfigMap Changes
```bash
# Create validation script
cat << 'EOF' > validate-config.sh
#!/bin/bash

NAMESPACE=${1:-development}
EXPECTED_LOG_LEVEL=${2:-warn}

echo "üîç Validating configuration changes in $NAMESPACE"

# Get pod name
POD_NAME=$(kubectl get pods -n $NAMESPACE -l app.kubernetes.io/name=my-app -o jsonpath='{.items[0].metadata.name}')

if [ -z "$POD_NAME" ]; then
  echo "‚ùå No pods found"
  exit 1
fi

echo "üìã Checking pod: $POD_NAME"

# Check ConfigMap content
echo "1. ConfigMap content:"
kubectl get configmap my-app-${NAMESPACE}-config -n $NAMESPACE -o jsonpath='{.data.app\.properties}' | grep log.level

# Check environment in pod
echo "2. Pod environment:"
kubectl exec -n $NAMESPACE $POD_NAME -- env | grep LOG_LEVEL

# Check mounted files
echo "3. Mounted configuration:"
kubectl exec -n $NAMESPACE $POD_NAME -- cat /etc/config/app.properties | grep log.level

# Test application response
echo "4. Application health:"
kubectl exec -n $NAMESPACE $POD_NAME -- curl -s http://localhost:8080/health

echo "‚úÖ Validation complete"
EOF

chmod +x validate-config.sh

# Run validation
./validate-config.sh development warn
./validate-config.sh production warn
```

## üìä Step 8: Monitor Configuration Impact

### Create Monitoring Dashboard Query
```bash
# Example queries for monitoring configuration changes

# 1. ConfigMap modification events
kubectl get events -n development --field-selector reason=ConfigMapUpdated

# 2. Pod restart events due to config changes
kubectl get events -n development --field-selector reason=Killing,involvedObject.kind=Pod

# 3. Application error rate after config changes
# (This would be in your monitoring system like Prometheus)
# rate(http_requests_total{status=~"5.."}[5m])
```

### Setup Configuration Change Alerts
```yaml
# Example Prometheus alert for ConfigMap changes
# configmap-alerts.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: configmap-alerts
  namespace: development
spec:
  groups:
  - name: configmap.rules
    rules:
    - alert: ConfigMapChanged
      expr: increase(kube_configmap_info[5m]) > 0
      for: 0m
      labels:
        severity: info
      annotations:
        summary: "ConfigMap {{ $labels.configmap }} changed in namespace {{ $labels.namespace }}"
        description: "ConfigMap has been modified, check if application restart is needed"
        
    - alert: PodRestartAfterConfigChange
      expr: increase(kube_pod_container_status_restarts_total[5m]) > 0
      for: 1m
      labels:
        severity: warning
      annotations:
        summary: "Pod {{ $labels.pod }} restarted in namespace {{ $labels.namespace }}"
        description: "Pod restarted possibly due to configuration changes"
```

## ‚úÖ Success Criteria

### ‚úÖ Configuration Update Checklist
- [ ] ConfigMap successfully updated using multiple methods
- [ ] Application restarted to pick up new configuration
- [ ] New configuration values visible in pod environment
- [ ] Application health checks passing after restart
- [ ] No service disruption during production updates
- [ ] Configuration changes properly validated
- [ ] Monitoring and alerting configured for config changes

### ‚úÖ Validation Commands
```bash
# All these should succeed:
kubectl get configmap my-app-dev-config -n development -o yaml
kubectl exec -n development deployment/my-app-dev -- env | grep LOG_LEVEL
kubectl exec -n development deployment/my-app-dev -- curl -f http://localhost:8080/health
kubectl get pods -n development -l app.kubernetes.io/name=my-app
```

## üßπ Cleanup

### Restore Original Configuration
```bash
# Restore from backup if needed
kubectl apply -f configmap-backup.yaml

# Restart to pick up original config
kubectl rollout restart deployment/my-app-dev -n development
```

## üéì Key Takeaways

### What You've Learned
1. **ConfigMap Update Methods**: kubectl patch, edit, and replace strategies
2. **Application Restart Patterns**: Rolling restart, scaling, and checksum triggers
3. **Production Safety**: Safe update procedures for production environments
4. **Validation Techniques**: Verifying configuration changes are applied correctly
5. **Monitoring Integration**: Tracking configuration changes and their impact

This exercise demonstrates comprehensive ConfigMap management, from simple updates to production-ready deployment strategies with proper validation and monitoring.

## ‚û°Ô∏è Next Steps
Proceed to [3. Modify Helm values and upgrade](3.%20Modify-Helm-Values-and-Upgrade.md) to learn how to manage configuration changes through Helm's upgrade mechanism.