# 4. Use Kustomize for Environment-Specific Configs

## üéØ Learning Objectives
- [ ] Integrate Kustomize with existing Helm deployments
- [ ] Create environment-specific configurations using overlays
- [ ] Implement post-rendering with Kustomize
- [ ] Manage complex multi-environment deployments
- [ ] Combine Helm templating with Kustomize transformations

## üìã Prerequisites
- Helm deployment from previous exercises
- Basic understanding of Kustomize concepts
- kubectl with Kustomize support
- Multiple environment namespaces

## üèóÔ∏è Step 1: Setup Kustomize Structure for Helm Integration

### Create Directory Structure
```bash
# Create Kustomize structure
mkdir -p kustomize-helm-integration/{base,overlays/{development,staging,production}}

cd kustomize-helm-integration

# Directory structure:
# kustomize-helm-integration/
# ‚îú‚îÄ‚îÄ base/
# ‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
# ‚îî‚îÄ‚îÄ overlays/
#     ‚îú‚îÄ‚îÄ development/
#     ‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
#     ‚îú‚îÄ‚îÄ staging/
#     ‚îÇ   ‚îî‚îÄ‚îÄ kustomization.yaml
#     ‚îî‚îÄ‚îÄ production/
#         ‚îî‚îÄ‚îÄ kustomization.yaml
```

### Generate Base Manifests from Helm
```bash
# Generate base Kubernetes manifests from Helm chart
helm template my-app ../my-app \
  --values ../my-app/values.yaml \
  --output-dir ./base \
  --include-crds

# Flatten the generated structure
find ./base -name "*.yaml" -exec mv {} ./base/ \;
find ./base -type d -empty -delete

# Rename files for clarity
cd base
for file in *.yaml; do
  if [ -f "$file" ]; then
    # Extract kind and rename
    kind=$(grep "^kind:" "$file" | head -1 | cut -d: -f2 | tr -d ' ' | tr '[:upper:]' '[:lower:]')
    mv "$file" "${kind}.yaml" 2>/dev/null || true
  fi
done
cd ..
```

### Create Base Kustomization
```yaml
# base/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: my-app-base
  annotations:
    config.kubernetes.io/local-config: "true"

resources:
  - deployment.yaml
  - service.yaml
  - configmap.yaml
  - serviceaccount.yaml

# Base labels for all environments
commonLabels:
  app.kubernetes.io/part-of: my-app-system
  app.kubernetes.io/managed-by: kustomize-helm
  team: platform

# Base annotations
commonAnnotations:
  config.source: helm-template
  config.tool: kustomize

# Default image settings
images:
  - name: my-app
    newTag: latest

# Base configuration
configMapGenerator:
  - name: environment-config
    literals:
      - DEPLOYMENT_METHOD=kustomize-helm
      - CONFIG_VERSION=1.0.0
```

## üåç Step 2: Development Environment Overlay

### Development Configuration
```yaml
# overlays/development/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: my-app-development
  annotations:
    environment: development

resources:
  - ../../base

# Development naming
namePrefix: dev-
nameSuffix: -kustomize

# Development labels and annotations
commonLabels:
  environment: development
  tier: non-production
  cost-center: development

commonAnnotations:
  environment: development
  auto-cleanup: "true"
  developer-access: "enabled"

# Development image
images:
  - name: my-app
    newTag: dev-latest

# Development replicas
replicas:
  - name: deployment
    count: 1

# Development configuration overrides
configMapGenerator:
  - name: environment-config
    behavior: merge
    literals:
      - ENVIRONMENT=development
      - LOG_LEVEL=debug
      - DEBUG_MODE=true
      - METRICS_ENABLED=false
      - DATABASE_URL=postgres://dev-db:5432/myapp_dev

# Development resource patches
patches:
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: deployment
      spec:
        template:
          spec:
            containers:
            - name: my-app
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 200m
                  memory: 256Mi
              env:
              - name: ENVIRONMENT
                value: development
              - name: NODE_ENV
                value: development
    target:
      kind: Deployment

  # Add development ingress
  - patch: |-
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: dev-ingress
        annotations:
          nginx.ingress.kubernetes.io/rewrite-target: /
          nginx.ingress.kubernetes.io/cors-allow-origin: "*"
      spec:
        rules:
        - host: dev-my-app.local
          http:
            paths:
            - path: /
              pathType: Prefix
              backend:
                service:
                  name: service
                  port:
                    number: 80
    target:
      kind: Ingress
```

### Development Additional Resources
```yaml
# overlays/development/dev-debug-tools.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: debug-tools
  labels:
    app.kubernetes.io/name: debug-tools
    app.kubernetes.io/component: development-tools
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: debug-tools
  template:
    metadata:
      labels:
        app.kubernetes.io/name: debug-tools
    spec:
      containers:
      - name: debug-tools
        image: nicolaka/netshoot:latest
        command:
        - sleep
        - "3600"
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 100m
            memory: 128Mi

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: development-scripts
data:
  test-connectivity.sh: |
    #!/bin/bash
    echo "Testing connectivity to application..."
    curl -v http://dev-service-kustomize/health
    
  debug-database.sh: |
    #!/bin/bash
    echo "Database connection test..."
    pg_isready -h dev-db -p 5432
```

### Update Development Kustomization
```yaml
# overlays/development/kustomization.yaml (updated)
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: my-app-development

resources:
  - ../../base
  - dev-debug-tools.yaml

namePrefix: dev-
nameSuffix: -kustomize

commonLabels:
  environment: development
  tier: non-production

images:
  - name: my-app
    newTag: dev-latest

replicas:
  - name: deployment
    count: 1

configMapGenerator:
  - name: environment-config
    behavior: merge
    literals:
      - ENVIRONMENT=development
      - LOG_LEVEL=debug
      - DEBUG_MODE=true

patches:
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: deployment
      spec:
        template:
          spec:
            containers:
            - name: my-app
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 200m
                  memory: 256Mi
              env:
              - name: ENVIRONMENT
                value: development
              - name: ENABLE_DEBUG_LOGS
                value: "true"
    target:
      kind: Deployment
```

## üîÑ Step 3: Staging Environment Overlay

### Staging Configuration
```yaml
# overlays/staging/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: my-app-staging
  annotations:
    environment: staging

resources:
  - ../../base

namePrefix: staging-
nameSuffix: -v2

commonLabels:
  environment: staging
  tier: pre-production
  testing: enabled

commonAnnotations:
  environment: staging
  qa-approved: pending
  load-testing: enabled

images:
  - name: my-app
    newTag: staging-1.2.0

replicas:
  - name: deployment
    count: 2

configMapGenerator:
  - name: environment-config
    behavior: merge
    literals:
      - ENVIRONMENT=staging
      - LOG_LEVEL=info
      - DEBUG_MODE=false
      - METRICS_ENABLED=true
      - DATABASE_URL=postgres://staging-db:5432/myapp_staging
      - CACHE_ENABLED=true

# Staging-specific patches
patches:
  # Resource allocation similar to production but smaller
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: deployment
      spec:
        template:
          spec:
            containers:
            - name: my-app
              resources:
                requests:
                  cpu: 250m
                  memory: 256Mi
                limits:
                  cpu: 500m
                  memory: 512Mi
              env:
              - name: ENVIRONMENT
                value: staging
              - name: PERFORMANCE_TESTING
                value: "true"
    target:
      kind: Deployment

  # Add staging ingress with load balancer
  - patch: |-
      apiVersion: v1
      kind: Service
      metadata:
        name: service
        annotations:
          service.beta.kubernetes.io/aws-load-balancer-type: nlb
      spec:
        type: LoadBalancer
    target:
      kind: Service

  # Add HPA for staging
  - patch: |-
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: staging-hpa
      spec:
        scaleTargetRef:
          apiVersion: apps/v1
          kind: Deployment
          name: deployment
        minReplicas: 2
        maxReplicas: 6
        metrics:
        - type: Resource
          resource:
            name: cpu
            target:
              type: Utilization
              averageUtilization: 70
    target:
      kind: HorizontalPodAutoscaler
```

### Staging Load Testing Configuration
```yaml
# overlays/staging/load-test.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: load-test
  labels:
    app.kubernetes.io/name: load-test
    app.kubernetes.io/component: testing
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: load-test
        image: loadimpact/k6:latest
        command:
        - k6
        - run
        - --vus=10
        - --duration=5m
        - /scripts/load-test.js
        env:
        - name: TARGET_URL
          value: http://staging-service-v2/
        volumeMounts:
        - name: load-test-script
          mountPath: /scripts
      volumes:
      - name: load-test-script
        configMap:
          name: load-test-config

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: load-test-config
data:
  load-test.js: |
    import http from 'k6/http';
    import { check } from 'k6';
    
    export default function() {
      let response = http.get(__ENV.TARGET_URL + 'health');
      check(response, {
        'status is 200': (r) => r.status === 200,
        'response time < 500ms': (r) => r.timings.duration < 500,
      });
    }
```

## üè≠ Step 4: Production Environment Overlay

### Production Configuration
```yaml
# overlays/production/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

metadata:
  name: my-app-production
  annotations:
    environment: production
    backup-policy: daily

resources:
  - ../../base
  - production-monitoring.yaml
  - production-security.yaml

# Clean production naming (no prefix/suffix)
commonLabels:
  environment: production
  tier: production
  criticality: high
  backup: enabled
  monitoring: enabled

commonAnnotations:
  environment: production
  backup-schedule: "0 2 * * *"
  monitoring-tier: critical
  sla-tier: gold

images:
  - name: my-app
    newTag: v1.3.0  # Stable production version

replicas:
  - name: deployment
    count: 5

configMapGenerator:
  - name: environment-config
    behavior: replace
    literals:
      - ENVIRONMENT=production
      - LOG_LEVEL=warn
      - DEBUG_MODE=false
      - METRICS_ENABLED=true
      - DATABASE_URL=postgres://prod-db:5432/myapp_prod
      - CACHE_ENABLED=true
      - AUDIT_ENABLED=true
      - PERFORMANCE_MONITORING=true

# Production patches with high availability and security
patches:
  # Production resource allocation and security
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: deployment
      spec:
        strategy:
          type: RollingUpdate
          rollingUpdate:
            maxSurge: 2
            maxUnavailable: 1
        template:
          spec:
            affinity:
              podAntiAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchLabels:
                      app.kubernetes.io/name: my-app
                  topologyKey: kubernetes.io/hostname
            securityContext:
              runAsNonRoot: true
              runAsUser: 1000
              fsGroup: 2000
            containers:
            - name: my-app
              securityContext:
                allowPrivilegeEscalation: false
                readOnlyRootFilesystem: true
                capabilities:
                  drop:
                  - ALL
              resources:
                requests:
                  cpu: 500m
                  memory: 1Gi
                limits:
                  cpu: 2000m
                  memory: 2Gi
              env:
              - name: ENVIRONMENT
                value: production
              - name: NODE_ENV
                value: production
              livenessProbe:
                httpGet:
                  path: /health
                  port: 8080
                initialDelaySeconds: 60
                periodSeconds: 30
                timeoutSeconds: 10
                failureThreshold: 3
              readinessProbe:
                httpGet:
                  path: /ready
                  port: 8080
                initialDelaySeconds: 20
                periodSeconds: 10
                timeoutSeconds: 5
                failureThreshold: 2
    target:
      kind: Deployment

  # Production service with load balancer
  - patch: |-
      apiVersion: v1
      kind: Service
      metadata:
        name: service
        annotations:
          service.beta.kubernetes.io/aws-load-balancer-type: nlb
          service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
      spec:
        type: LoadBalancer
    target:
      kind: Service

  # Production HPA with advanced scaling
  - patch: |-
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: production-hpa
      spec:
        scaleTargetRef:
          apiVersion: apps/v1
          kind: Deployment
          name: deployment
        minReplicas: 5
        maxReplicas: 20
        metrics:
        - type: Resource
          resource:
            name: cpu
            target:
              type: Utilization
              averageUtilization: 70
        - type: Resource
          resource:
            name: memory
            target:
              type: Utilization
              averageUtilization: 80
        behavior:
          scaleDown:
            stabilizationWindowSeconds: 300
            policies:
            - type: Percent
              value: 10
              periodSeconds: 60
          scaleUp:
            stabilizationWindowSeconds: 60
            policies:
            - type: Percent
              value: 50
              periodSeconds: 60
    target:
      kind: HorizontalPodAutoscaler
```

### Production Monitoring Resources
```yaml
# overlays/production/production-monitoring.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: my-app-metrics
  labels:
    app.kubernetes.io/name: my-app
    app.kubernetes.io/component: monitoring
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: my-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: my-app-alerts
  labels:
    app.kubernetes.io/name: my-app
    app.kubernetes.io/component: alerting
spec:
  groups:
  - name: my-app.rules
    rules:
    - alert: HighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High error rate detected"
        description: "Error rate is above 10% for 5 minutes"
        
    - alert: HighMemoryUsage
      expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage"
        description: "Memory usage is above 90% for 5 minutes"
```

### Production Security Resources
```yaml
# overlays/production/production-security.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: my-app-network-policy
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: my-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: database
    ports:
    - protocol: TCP
      port: 5432
  - to: []
    ports:
    - protocol: UDP
      port: 53  # DNS

---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: my-app-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: my-app
```

## üîÑ Step 5: Helm Post-Rendering Integration

### Create Post-Rendering Script
```bash
# Create Helm post-renderer script
cat << 'EOF' > helm-kustomize-post-renderer.sh
#!/bin/bash
# Helm post-renderer that uses Kustomize

set -e

# Read Helm output and save to temporary file
TEMP_DIR=$(mktemp -d)
MANIFEST_FILE="$TEMP_DIR/helm-output.yaml"

cat > "$MANIFEST_FILE"

# Create temporary kustomization
cat > "$TEMP_DIR/kustomization.yaml" << KUSTOMIZATION_EOF
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - helm-output.yaml

# Environment-specific transformations
namePrefix: ${NAME_PREFIX:-}
nameSuffix: ${NAME_SUFFIX:-}

commonLabels:
  managed-by: helm-kustomize
  environment: ${ENVIRONMENT:-default}

# Apply any patches from environment variable
${KUSTOMIZE_PATCHES:-}
KUSTOMIZATION_EOF

# Apply Kustomize transformations
kubectl kustomize "$TEMP_DIR"

# Cleanup
rm -rf "$TEMP_DIR"
EOF

chmod +x helm-kustomize-post-renderer.sh
```

### Use Post-Rendering with Helm
```bash
# Deploy with post-rendering for development
ENVIRONMENT=development \
NAME_PREFIX=dev- \
NAME_SUFFIX=-kustomize \
helm upgrade --install my-app-dev ../my-app \
  --namespace development \
  --values ../my-app/values-dev.yaml \
  --post-renderer ./helm-kustomize-post-renderer.sh \
  --wait

# Deploy with post-rendering for production
ENVIRONMENT=production \
KUSTOMIZE_PATCHES='
patches:
  - patch: |-
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: not-used
      spec:
        replicas: 5
    target:
      kind: Deployment
' \
helm upgrade --install my-app-prod ../my-app \
  --namespace production \
  --values ../my-app/values-prod.yaml \
  --post-renderer ./helm-kustomize-post-renderer.sh \
  --wait
```

## ‚ö° Step 6: Deploy Using Pure Kustomize

### Deploy Development Environment
```bash
# Create development namespace
kubectl create namespace development-kustomize

# Deploy using Kustomize
kubectl apply -k overlays/development --namespace development-kustomize

# Verify deployment
kubectl get all -n development-kustomize
kubectl get configmaps -n development-kustomize
```

### Deploy Staging Environment
```bash
# Create staging namespace
kubectl create namespace staging-kustomize

# Deploy staging
kubectl apply -k overlays/staging --namespace staging-kustomize

# Verify deployment
kubectl get all -n staging-kustomize
kubectl get hpa -n staging-kustomize
```

### Deploy Production Environment
```bash
# Create production namespace
kubectl create namespace production-kustomize

# Deploy production
kubectl apply -k overlays/production --namespace production-kustomize

# Verify deployment
kubectl get all -n production-kustomize
kubectl get networkpolicy -n production-kustomize
kubectl get servicemonitor -n production-kustomize
```

## üß™ Step 7: Validate Environment-Specific Configurations

### Configuration Verification Script
```bash
# Create verification script
cat << 'EOF' > verify-environments.sh
#!/bin/bash

verify_environment() {
    local env=$1
    local namespace=$2
    
    echo "üîç Verifying $env environment in namespace $namespace"
    
    # Check pods are running
    echo "1. Pod Status:"
    kubectl get pods -n $namespace -l app.kubernetes.io/name=my-app
    
    # Check environment-specific labels
    echo "2. Environment Labels:"
    kubectl get pods -n $namespace -l environment=$env --show-labels | head -2
    
    # Check resource allocation
    echo "3. Resource Requests/Limits:"
    kubectl get pods -n $namespace -o jsonpath='{.items[0].spec.containers[0].resources}' | jq .
    
    # Check environment variables
    echo "4. Environment Variables:"
    POD_NAME=$(kubectl get pods -n $namespace -l app.kubernetes.io/name=my-app -o jsonpath='{.items[0].metadata.name}')
    kubectl exec -n $namespace $POD_NAME -- env | grep -E "(ENVIRONMENT|LOG_LEVEL|DEBUG_MODE)"
    
    # Check ConfigMaps
    echo "5. ConfigMaps:"
    kubectl get configmaps -n $namespace
    
    echo "‚úÖ $env verification complete\n"
}

# Verify all environments
verify_environment "development" "development-kustomize"
verify_environment "staging" "staging-kustomize"  
verify_environment "production" "production-kustomize"
EOF

chmod +x verify-environments.sh
./verify-environments.sh
```

### Environment Comparison
```bash
# Compare configurations across environments
echo "üìä Environment Configuration Comparison"
echo "======================================="

echo "Replica Counts:"
echo "Development: $(kubectl get deployment -n development-kustomize -o jsonpath='{.items[0].spec.replicas}')"
echo "Staging: $(kubectl get deployment -n staging-kustomize -o jsonpath='{.items[0].spec.replicas}')"
echo "Production: $(kubectl get deployment -n production-kustomize -o jsonpath='{.items[0].spec.replicas}')"

echo -e "\nImage Tags:"
echo "Development: $(kubectl get deployment -n development-kustomize -o jsonpath='{.items[0].spec.template.spec.containers[0].image}')"
echo "Staging: $(kubectl get deployment -n staging-kustomize -o jsonpath='{.items[0].spec.template.spec.containers[0].image}')"
echo "Production: $(kubectl get deployment -n production-kustomize -o jsonpath='{.items[0].spec.template.spec.containers[0].image}')"

echo -e "\nResource Requests (CPU):"
echo "Development: $(kubectl get deployment -n development-kustomize -o jsonpath='{.items[0].spec.template.spec.containers[0].resources.requests.cpu}')"
echo "Staging: $(kubectl get deployment -n staging-kustomize -o jsonpath='{.items[0].spec.template.spec.containers[0].resources.requests.cpu}')"
echo "Production: $(kubectl get deployment -n production-kustomize -o jsonpath='{.items[0].spec.template.spec.containers[0].resources.requests.cpu}')"
```

## üîÑ Step 8: Update and Sync Configurations

### Configuration Update Workflow
```bash
# Create update script
cat << 'EOF' > update-config.sh
#!/bin/bash

ENVIRONMENT=${1:-development}
CONFIG_KEY=${2:-LOG_LEVEL}
CONFIG_VALUE=${3:-info}

echo "üîÑ Updating $CONFIG_KEY to $CONFIG_VALUE in $ENVIRONMENT"

# Update the kustomization file
OVERLAY_PATH="overlays/$ENVIRONMENT/kustomization.yaml"

# Backup current configuration
cp "$OVERLAY_PATH" "$OVERLAY_PATH.backup"

# Update the configuration
sed -i "s/- $CONFIG_KEY=.*$/- $CONFIG_KEY=$CONFIG_VALUE/" "$OVERLAY_PATH"

echo "‚úÖ Configuration updated in $OVERLAY_PATH"

# Apply the changes
kubectl apply -k "overlays/$ENVIRONMENT" --namespace "${ENVIRONMENT}-kustomize"

# Restart deployment to pick up changes
kubectl rollout restart deployment -n "${ENVIRONMENT}-kustomize"

echo "‚úÖ Configuration applied and deployment restarted"
EOF

chmod +x update-config.sh

# Example usage
./update-config.sh development LOG_LEVEL error
./update-config.sh staging LOG_LEVEL warn
```

### Multi-Environment Sync
```bash
# Sync configuration across environments
cat << 'EOF' > sync-environments.sh
#!/bin/bash

SOURCE_ENV=${1:-development}
TARGET_ENV=${2:-staging}

echo "üîÑ Syncing configuration from $SOURCE_ENV to $TARGET_ENV"

# Extract common configuration from source
SOURCE_CONFIG=$(grep -A 20 "configMapGenerator:" "overlays/$SOURCE_ENV/kustomization.yaml")

# Create backup
cp "overlays/$TARGET_ENV/kustomization.yaml" "overlays/$TARGET_ENV/kustomization.yaml.backup"

# Update target environment (simplified - in practice, use more sophisticated merging)
echo "Configuration sync requires manual review and merge"
echo "Source configuration:"
echo "$SOURCE_CONFIG"

echo "‚úÖ Review and manually merge configurations as needed"
EOF

chmod +x sync-environments.sh
```

## ‚úÖ Success Criteria

### ‚úÖ Environment Configuration Checklist
- [ ] Base Kustomization created from Helm templates
- [ ] Development overlay with debug configurations
- [ ] Staging overlay with testing and load balancing
- [ ] Production overlay with security and monitoring
- [ ] Environment-specific resource allocation working
- [ ] All environments deployed successfully
- [ ] Configuration differences verified between environments
- [ ] Post-rendering integration working with Helm
- [ ] Update and sync workflows functional

### ‚úÖ Validation Commands
```bash
# All these should succeed:
kubectl get all -n development-kustomize
kubectl get all -n staging-kustomize  
kubectl get all -n production-kustomize
kubectl kustomize overlays/development --dry-run=client
kubectl kustomize overlays/staging --dry-run=client
kubectl kustomize overlays/production --dry-run=client
```

## üßπ Cleanup

### Remove Kustomize Deployments
```bash
# Delete all Kustomize deployments
kubectl delete -k overlays/development --namespace development-kustomize
kubectl delete -k overlays/staging --namespace staging-kustomize
kubectl delete -k overlays/production --namespace production-kustomize

# Delete namespaces
kubectl delete namespace development-kustomize staging-kustomize production-kustomize
```

## üéì Key Takeaways

### What You've Learned
1. **Helm-Kustomize Integration**: Combining Helm templating with Kustomize transformations
2. **Environment Management**: Creating sophisticated environment-specific configurations
3. **Post-Rendering**: Using Kustomize as a Helm post-renderer for advanced transformations
4. **Configuration Layering**: Base configurations with environment-specific overlays
5. **Operational Workflows**: Update, sync, and deployment procedures

### Benefits Achieved
- **Consistency**: Base configuration ensures consistency across environments
- **Flexibility**: Environment-specific overlays provide necessary customization
- **Maintainability**: Changes to base affect all environments, overlay changes are isolated
- **Scalability**: Easy to add new environments or modify existing ones
- **Integration**: Works seamlessly with existing Helm workflows

This exercise demonstrates how to effectively combine Helm's templating power with Kustomize's transformation capabilities for comprehensive multi-environment management.

## ‚û°Ô∏è Next Steps
Proceed to [5. Monitor deployment via CloudWatch logs](5.%20Monitor-Deployment-via-CloudWatch-Logs.md) to learn how to set up comprehensive monitoring and logging for your Kustomized deployments.