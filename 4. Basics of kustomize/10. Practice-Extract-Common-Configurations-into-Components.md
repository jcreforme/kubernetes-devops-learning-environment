# 10. Practice: Extract Common Configurations into Components

## üéØ Learning Objectives
- [ ] Identify common configuration patterns across projects
- [ ] Refactor existing Kustomizations into reusable components
- [ ] Extract shared functionality while maintaining customization flexibility
- [ ] Build a component library from existing infrastructure
- [ ] Master component extraction methodology and best practices

## üîç Component Extraction Methodology

### Phase 1: Pattern Identification
```
Configuration Analysis Process:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Audit Existing   ‚îÇ Survey all kustomizations           ‚îÇ
‚îÇ 2. Identify Patterns ‚îÇ Find repeated configurations        ‚îÇ
‚îÇ 3. Assess Variations ‚îÇ Understand customization needs      ‚îÇ
‚îÇ 4. Define Components ‚îÇ Create reusable abstractions        ‚îÇ
‚îÇ 5. Extract & Test    ‚îÇ Implement and validate components   ‚îÇ
‚îÇ 6. Migrate Projects  ‚îÇ Replace duplications with components ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Common Patterns to Extract:
‚îú‚îÄ‚îÄ Monitoring Stack     ‚îÇ Prometheus + Grafana everywhere
‚îú‚îÄ‚îÄ Database Patterns    ‚îÇ PostgreSQL/MySQL + backup
‚îú‚îÄ‚îÄ Security Policies    ‚îÇ Network policies + RBAC
‚îú‚îÄ‚îÄ Ingress Configuration‚îÇ Standard ingress + TLS
‚îú‚îÄ‚îÄ Logging Pipeline     ‚îÇ Fluentd/Fluent Bit + storage
‚îî‚îÄ‚îÄ Resource Policies    ‚îÇ Quotas + limits + priorities
```

## üïµÔ∏è Practical Exercise: Multi-Project Analysis

### Scenario: Organization with 5 Similar Projects
```
Current State - Project Duplication:
ecommerce-api/
‚îú‚îÄ‚îÄ overlays/production/
‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.yaml      ‚Üê Repeated
‚îÇ   ‚îú‚îÄ‚îÄ postgres.yaml        ‚Üê Repeated
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml         ‚Üê Similar
‚îÇ   ‚îî‚îÄ‚îÄ security.yaml       ‚Üê Repeated

user-service/
‚îú‚îÄ‚îÄ overlays/production/
‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.yaml      ‚Üê Repeated (same)
‚îÇ   ‚îú‚îÄ‚îÄ mysql.yaml           ‚Üê Different DB, same pattern
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml         ‚Üê Similar
‚îÇ   ‚îî‚îÄ‚îÄ security.yaml       ‚Üê Repeated (same)

inventory-api/
‚îú‚îÄ‚îÄ overlays/production/
‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.yaml      ‚Üê Repeated (same)
‚îÇ   ‚îú‚îÄ‚îÄ postgres.yaml        ‚Üê Repeated (same)
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml         ‚Üê Similar
‚îÇ   ‚îî‚îÄ‚îÄ security.yaml       ‚Üê Repeated (same)

analytics-service/
‚îú‚îÄ‚îÄ overlays/production/
‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.yaml      ‚Üê Repeated (same)
‚îÇ   ‚îú‚îÄ‚îÄ postgres.yaml        ‚Üê Repeated (same)
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml         ‚Üê Similar
‚îÇ   ‚îî‚îÄ‚îÄ security.yaml       ‚Üê Repeated (same)

notification-service/
‚îú‚îÄ‚îÄ overlays/production/
‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.yaml      ‚Üê Repeated (same)
‚îÇ   ‚îú‚îÄ‚îÄ redis.yaml           ‚Üê Different storage
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml         ‚Üê Similar
‚îÇ   ‚îî‚îÄ‚îÄ security.yaml       ‚Üê Repeated (same)
```

### Analysis Results
```bash
# Analysis script to identify duplication
#!/bin/bash
# scripts/analyze-duplication.sh

echo "üîç Analyzing configuration duplication..."

find . -name "monitoring.yaml" -exec md5sum {} \; | sort
find . -name "security.yaml" -exec md5sum {} \; | sort  
find . -name "*postgres*.yaml" -exec md5sum {} \; | sort
find . -name "ingress.yaml" -exec md5sum {} \; | sort

# Output shows:
# monitoring.yaml: 4 identical files (80% duplication)
# security.yaml: 5 identical files (100% duplication)  
# postgres.yaml: 3 identical files (75% of postgres users)
# ingress.yaml: Similar patterns with minor variations
```

## üèóÔ∏è Step 1: Extract Monitoring Component

### Analyze Current Monitoring Configurations
```yaml
# Current monitoring.yaml (repeated across projects)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:v2.40.0
        ports:
        - containerPort: 9090
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.retention.time=30d'  # Varies: 7d, 15d, 30d
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        resources:
          requests:
            memory: 1Gi     # Varies: 512Mi, 1Gi, 2Gi  
            cpu: 500m       # Varies: 200m, 500m, 1000m
      volumes:
      - name: config
        configMap:
          name: prometheus-config

---
apiVersion: v1
kind: ConfigMap  
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    scrape_configs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

### Create Monitoring Component
```yaml
# components/monitoring/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1alpha1
kind: Component

metadata:
  name: prometheus-monitoring
  annotations:
    component.version: v1.0.0
    component.description: "Standard Prometheus monitoring stack"

resources:
  - prometheus-deployment.yaml
  - prometheus-service.yaml
  - prometheus-configmap.yaml
  - grafana-deployment.yaml
  - grafana-service.yaml

commonLabels:
  component: monitoring-stack
  monitoring-type: prometheus

# Configurable parameters
images:
  - name: prometheus
    newTag: v2.40.0
  - name: grafana
    newTag: 9.3.0

# Default configuration - can be overridden
configMapGenerator:
  - name: monitoring-config
    literals:
      - RETENTION_DAYS=30
      - SCRAPE_INTERVAL=15s
      - MEMORY_REQUEST=1Gi
      - CPU_REQUEST=500m

# Variables for customization
vars:
  - name: RETENTION_PERIOD
    objref:
      kind: ConfigMap
      name: monitoring-config
      apiVersion: v1
    fieldref:
      fieldpath: data.RETENTION_DAYS
```

### Monitoring Component Resources
```yaml
# components/monitoring/prometheus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/component: metrics-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: prometheus
  template:
    metadata:
      labels:
        app.kubernetes.io/name: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:v2.40.0
        ports:
        - containerPort: 9090
          name: web
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus/'
        - '--storage.tsdb.retention.time=$(RETENTION_PERIOD)d'
        - '--web.enable-lifecycle'
        env:
        - name: RETENTION_PERIOD
          valueFrom:
            configMapKeyRef:
              name: monitoring-config
              key: RETENTION_DAYS
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: storage
          mountPath: /prometheus
        resources:
          requests:
            memory: $(MEMORY_REQUEST)
            cpu: $(CPU_REQUEST)
          limits:
            memory: 2Gi  # Always reasonable limit
            cpu: 1000m
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 15
        readinessProbe:
          httpGet:
            path: /-/ready  
            port: 9090
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: storage
        emptyDir: {}
```

### Component Configuration Template
```yaml
# components/monitoring/prometheus-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: $(SCRAPE_INTERVAL)
      evaluation_interval: $(SCRAPE_INTERVAL)
      external_labels:
        cluster: '$(CLUSTER_NAME)'
        environment: '$(ENVIRONMENT)'
    
    rule_files:
      - /etc/prometheus/rules/*.yml
    
    scrape_configs:
    # Kubernetes API server
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
    
    # Kubernetes nodes
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
    
    # Kubernetes pods with prometheus.io/scrape annotation
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
```

## üîê Step 2: Extract Security Policies Component

### Analyze Security Patterns
```yaml
# Current security.yaml (identical across all projects)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
apiVersion: networking.k8s.io/v1  
kind: NetworkPolicy
metadata:
  name: allow-dns
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - to: []
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP  
      port: 53

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list"]
```

### Create Security Component
```yaml
# components/security-policies/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1alpha1
kind: Component

metadata:
  name: security-policies
  annotations:
    component.version: v2.0.0
    component.description: "Standard security policies for all applications"

resources:
  - network-policies.yaml
  - rbac-policies.yaml
  - pod-security-policies.yaml

commonLabels:
  component: security-policies
  security-level: standard

# Configurable security levels
configMapGenerator:
  - name: security-config
    literals:
      - SECURITY_LEVEL=standard    # basic, standard, strict
      - NETWORK_POLICY_ENABLED=true
      - RBAC_ENABLED=true
      - PSP_ENABLED=true

vars:
  - name: SECURITY_LEVEL
    objref:
      kind: ConfigMap
      name: security-config
      apiVersion: v1
    fieldref:
      fieldpath: data.SECURITY_LEVEL
```

### Security Component Resources
```yaml
# components/security-policies/network-policies.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  annotations:
    policy.description: "Deny all ingress and egress by default"
    security.level: "$(SECURITY_LEVEL)"
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy  
metadata:
  name: allow-dns-access
  annotations:
    policy.description: "Allow DNS resolution for all pods"
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - to: []
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-same-namespace
  annotations:
    policy.description: "Allow communication within the same namespace"
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: $(CURRENT_NAMESPACE)

---
# Conditional strict policy (only if SECURITY_LEVEL=strict)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-monitoring
  annotations:
    policy.description: "Allow monitoring scraping"
spec:
  podSelector:
    matchLabels:
      prometheus.io/scrape: "true"
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090
```

## üóÑÔ∏è Step 3: Extract Database Components

### Database Pattern Analysis
```yaml
# Pattern 1: PostgreSQL (used by ecommerce-api, inventory-api, analytics-service)
# Pattern 2: MySQL (used by user-service)  
# Pattern 3: Redis (used by notification-service)

# Common database requirements:
- Persistent storage
- Backup solution
- Health checks
- Configuration management
- Connection pooling (for production)
```

### Create PostgreSQL Component
```yaml
# components/postgresql/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1alpha1
kind: Component

metadata:
  name: postgresql-database
  annotations:
    component.version: v3.1.0
    component.description: "Production-ready PostgreSQL with backup and monitoring"

resources:
  - postgresql-statefulset.yaml
  - postgresql-service.yaml
  - postgresql-configmap.yaml
  - backup-cronjob.yaml
  - pgbouncer.yaml  # Connection pooling

components:
  - ../monitoring  # Include monitoring for database

commonLabels:
  component: postgresql-database
  database-type: postgresql

# Database configuration
configMapGenerator:
  - name: postgresql-config
    literals:
      - POSTGRES_VERSION=14
      - MAX_CONNECTIONS=100
      - SHARED_BUFFERS=256MB
      - EFFECTIVE_CACHE_SIZE=1GB
      - MAINTENANCE_WORK_MEM=64MB
      - CHECKPOINT_COMPLETION_TARGET=0.7
      - BACKUP_ENABLED=true
      - BACKUP_SCHEDULE=0 2 * * *
      - STORAGE_SIZE=20Gi

# Production secrets template
secretGenerator:
  - name: postgresql-secrets
    literals:
      - postgres-password=$(POSTGRES_PASSWORD)
      - replication-password=$(REPLICATION_PASSWORD)
    type: Opaque

images:
  - name: postgresql
    newTag: "14.6"
  - name: pgbouncer
    newTag: "1.17"

vars:
  - name: POSTGRES_PASSWORD
    objref:
      kind: Secret
      name: postgresql-secrets
      apiVersion: v1
    fieldref:
      fieldpath: data.postgres-password
  - name: STORAGE_SIZE
    objref:
      kind: ConfigMap
      name: postgresql-config
      apiVersion: v1
    fieldref:
      fieldpath: data.STORAGE_SIZE
```

### PostgreSQL Component Resources
```yaml
# components/postgresql/postgresql-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
  labels:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: database
spec:
  serviceName: postgresql-headless
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
  template:
    metadata:
      labels:
        app.kubernetes.io/name: postgresql
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9187"
    spec:
      initContainers:
      - name: init-postgresql
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          chown -R 999:999 /var/lib/postgresql/data
          chmod 700 /var/lib/postgresql/data
        volumeMounts:
        - name: postgresql-data
          mountPath: /var/lib/postgresql/data
      containers:
      - name: postgresql
        image: postgres:14.6
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgresql-secrets
              key: postgres-password
        - name: POSTGRES_DB
          value: $(DATABASE_NAME)
        - name: POSTGRES_USER
          value: postgres
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        ports:
        - containerPort: 5432
          name: postgresql
        volumeMounts:
        - name: postgresql-data
          mountPath: /var/lib/postgresql/data
        - name: postgresql-config
          mountPath: /etc/postgresql
        resources:
          requests:
            memory: 1Gi
            cpu: 500m
          limits:
            memory: 2Gi
            cpu: 1000m
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 5
          periodSeconds: 5
      # PostgreSQL Exporter for monitoring
      - name: postgres-exporter
        image: prometheuscommunity/postgres-exporter:v0.11.1
        env:
        - name: DATA_SOURCE_NAME
          value: postgresql://postgres:$(POSTGRES_PASSWORD)@localhost:5432/postgres?sslmode=disable
        ports:
        - containerPort: 9187
          name: metrics
        resources:
          requests:
            memory: 64Mi
            cpu: 50m
          limits:
            memory: 128Mi
            cpu: 100m
      volumes:
      - name: postgresql-config
        configMap:
          name: postgresql-config
  volumeClaimTemplates:
  - metadata:
      name: postgresql-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: $(STORAGE_SIZE)
```

## üåê Step 4: Extract Ingress Component

### Ingress Pattern Analysis
```yaml
# Current ingress patterns show variations but common structure:

# Common elements:
- nginx ingress controller
- TLS termination
- Path-based routing
- CORS headers (for APIs)
- Rate limiting

# Variations:
- Host names (app-specific)
- TLS certificate sources
- Rate limiting rules
- Authentication requirements
```

### Create Flexible Ingress Component
```yaml
# components/ingress/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1alpha1
kind: Component

metadata:
  name: application-ingress
  annotations:
    component.version: v2.0.0
    component.description: "Configurable ingress with TLS and CORS support"

resources:
  - ingress.yaml
  - ingress-configmap.yaml

commonLabels:
  component: application-ingress
  ingress-class: nginx

# Configurable ingress options
configMapGenerator:
  - name: ingress-config
    literals:
      - TLS_ENABLED=true
      - CORS_ENABLED=true
      - RATE_LIMIT_ENABLED=true
      - RATE_LIMIT_RPS=10
      - CERT_MANAGER_ISSUER=letsencrypt-prod
      - INGRESS_CLASS=nginx

vars:
  - name: HOSTNAME
    objref:
      kind: ConfigMap
      name: ingress-config
      apiVersion: v1
    fieldref:
      fieldpath: data.HOSTNAME
  - name: TLS_SECRET_NAME
    objref:
      kind: ConfigMap
      name: ingress-config
      apiVersion: v1
    fieldref:
      fieldpath: data.TLS_SECRET_NAME
```

### Flexible Ingress Template
```yaml
# components/ingress/ingress.yaml  
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: application-ingress
  annotations:
    kubernetes.io/ingress.class: $(INGRESS_CLASS)
    nginx.ingress.kubernetes.io/ssl-redirect: "$(TLS_ENABLED)"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "$(TLS_ENABLED)"
    # CORS configuration (conditional)
    nginx.ingress.kubernetes.io/enable-cors: "$(CORS_ENABLED)"
    nginx.ingress.kubernetes.io/cors-allow-origin: "*"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, POST, PUT, DELETE, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization"
    # Rate limiting (conditional)  
    nginx.ingress.kubernetes.io/rate-limit: "$(RATE_LIMIT_RPS)"
    # TLS certificate management
    cert-manager.io/cluster-issuer: $(CERT_MANAGER_ISSUER)
spec:
  tls:
  - hosts:
    - $(HOSTNAME)
    secretName: $(TLS_SECRET_NAME)
  rules:
  - host: $(HOSTNAME)
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: $(SERVICE_NAME)
            port:
              number: $(SERVICE_PORT)
      # API path for microservices
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: $(API_SERVICE_NAME)
            port:
              number: $(API_SERVICE_PORT)
```

## üîÑ Step 5: Refactor Projects to Use Components

### Before: Traditional Kustomization
```yaml
# ecommerce-api/overlays/production/kustomization.yaml (before)
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - ../../base
  - monitoring.yaml      # 150 lines of monitoring config
  - postgres.yaml        # 100 lines of postgres config  
  - ingress.yaml         # 50 lines of ingress config
  - security.yaml        # 75 lines of security policies

commonLabels:
  app: ecommerce-api
  environment: production

# Total: 375+ lines of repeated configuration
```

### After: Component-Based Kustomization  
```yaml
# ecommerce-api/overlays/production/kustomization.yaml (after)
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - ../../base

# Reusable components
components:
  - ../../../components/monitoring
  - ../../../components/postgresql  
  - ../../../components/ingress
  - ../../../components/security-policies

commonLabels:
  app: ecommerce-api
  environment: production

# Component customization
configMapGenerator:
  - name: ingress-config
    behavior: merge
    literals:
      - HOSTNAME=api.ecommerce.company.com
      - SERVICE_NAME=ecommerce-api-service
      - SERVICE_PORT=8080
      - TLS_SECRET_NAME=ecommerce-api-tls
      
  - name: postgresql-config
    behavior: merge
    literals:
      - DATABASE_NAME=ecommerce
      - STORAGE_SIZE=50Gi
      - MAX_CONNECTIONS=200
      
  - name: monitoring-config
    behavior: merge  
    literals:
      - RETENTION_DAYS=90
      - MEMORY_REQUEST=2Gi
      - CPU_REQUEST=1000m

# Total: ~50 lines, 87% reduction in duplication
```

### Migration Script
```bash
#!/bin/bash
# scripts/migrate-to-components.sh

set -e

PROJECT_DIR=${1:-"."}
COMPONENTS_DIR="../../../components"

echo "üîÑ Migrating project to use components: $PROJECT_DIR"

# Backup current configuration
backup_dir="$PROJECT_DIR/backup-$(date +%Y%m%d)"
mkdir -p "$backup_dir"
cp -r "$PROJECT_DIR/overlays" "$backup_dir/"

# Function to migrate overlay
migrate_overlay() {
    local overlay_path=$1
    local overlay_name=$(basename "$overlay_path")
    
    echo "Migrating overlay: $overlay_name"
    
    # Create new kustomization.yaml
    cat > "$overlay_path/kustomization.yaml" << EOF
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - ../../base

components:
EOF

    # Add components based on existing files
    if [ -f "$overlay_path/monitoring.yaml" ]; then
        echo "  - $COMPONENTS_DIR/monitoring" >> "$overlay_path/kustomization.yaml"
        rm "$overlay_path/monitoring.yaml"
        echo "  ‚úÖ Replaced monitoring.yaml with component"
    fi
    
    if [ -f "$overlay_path/postgres.yaml" ] || [ -f "$overlay_path/postgresql.yaml" ]; then
        echo "  - $COMPONENTS_DIR/postgresql" >> "$overlay_path/kustomization.yaml"
        rm -f "$overlay_path/postgres.yaml" "$overlay_path/postgresql.yaml"
        echo "  ‚úÖ Replaced postgres.yaml with component"
    fi
    
    if [ -f "$overlay_path/security.yaml" ]; then
        echo "  - $COMPONENTS_DIR/security-policies" >> "$overlay_path/kustomization.yaml"
        rm "$overlay_path/security.yaml"
        echo "  ‚úÖ Replaced security.yaml with component"
    fi
    
    if [ -f "$overlay_path/ingress.yaml" ]; then
        echo "  - $COMPONENTS_DIR/ingress" >> "$overlay_path/kustomization.yaml"
        
        # Extract hostname from existing ingress for configuration
        hostname=$(yq e '.spec.rules[0].host' "$overlay_path/ingress.yaml" 2>/dev/null || echo "")
        service_name=$(yq e '.spec.rules[0].http.paths[0].backend.service.name' "$overlay_path/ingress.yaml" 2>/dev/null || echo "")
        
        if [ -n "$hostname" ]; then
            cat >> "$overlay_path/kustomization.yaml" << EOF

configMapGenerator:
  - name: ingress-config
    behavior: merge
    literals:
      - HOSTNAME=$hostname
      - SERVICE_NAME=$service_name
      - SERVICE_PORT=8080
EOF
        fi
        
        rm "$overlay_path/ingress.yaml"
        echo "  ‚úÖ Replaced ingress.yaml with component"
    fi
    
    # Test the migration
    echo "  üß™ Testing migrated configuration..."
    kubectl kustomize "$overlay_path" --dry-run=client > /dev/null || {
        echo "  ‚ùå Migration validation failed for $overlay_name"
        return 1
    }
    
    echo "  ‚úÖ Migration completed successfully for $overlay_name"
}

# Migrate all overlays
for overlay_path in "$PROJECT_DIR"/overlays/*/; do
    if [ -d "$overlay_path" ]; then
        migrate_overlay "$overlay_path"
    fi
done

echo "üéâ Migration completed! Backup saved to: $backup_dir"
echo "üìä To see the reduction in configuration size:"
echo "    Before: $(find $backup_dir -name '*.yaml' -exec wc -l {} + | tail -n 1)"  
echo "    After:  $(find $PROJECT_DIR/overlays -name '*.yaml' -exec wc -l {} + | tail -n 1)"
```

## üìä Measuring Component Extraction Success

### Configuration Analysis Script
```bash
#!/bin/bash
# scripts/component-impact-analysis.sh

echo "üìä Component Extraction Impact Analysis"
echo "========================================"

# Before migration (from backups)
backup_files=$(find . -path "*/backup-*" -name "*.yaml" | wc -l)
backup_lines=$(find . -path "*/backup-*" -name "*.yaml" -exec wc -l {} + | tail -n 1 | awk '{print $1}')

# After migration (current state)  
current_files=$(find . -path "*/overlays/*" -name "*.yaml" | wc -l)
current_lines=$(find . -path "*/overlays/*" -name "*.yaml" -exec wc -l {} + | tail -n 1 | awk '{print $1}')

# Component library
component_files=$(find components -name "*.yaml" | wc -l)
component_lines=$(find components -name "*.yaml" -exec wc -l {} + | tail -n 1 | awk '{print $1}')

echo "Configuration Files:"
echo "  Before: $backup_files files"
echo "  After:  $current_files files"
echo "  Components: $component_files files"
echo ""

echo "Lines of Configuration:"  
echo "  Before: $backup_lines lines"
echo "  After:  $current_lines lines"
echo "  Components: $component_lines lines"
echo ""

# Calculate savings
total_reduction=$(($backup_lines - $current_lines))
percentage_reduction=$(($total_reduction * 100 / $backup_lines))

echo "Impact:"
echo "  Reduction: $total_reduction lines ($percentage_reduction%)"
echo "  Reusability: $(($component_lines / 5)) lines of config shared across projects"
echo "  Maintainability: Components can be updated once, applied everywhere"
```

### Component Usage Tracking
```bash
#!/bin/bash
# scripts/track-component-usage.sh

echo "üîç Component Usage Analysis"
echo "=========================="

# Track which components are used where
find . -name "kustomization.yaml" -path "*/overlays/*" -exec grep -l "components:" {} \; | \
while read file; do
    echo "Project: $(echo $file | cut -d/ -f1-2)"
    grep -A 10 "components:" "$file" | grep "^  -" | sed 's/^  - /  ‚úì /'
    echo ""
done

echo "Component Popularity:"
components=$(find . -name "kustomization.yaml" -path "*/overlays/*" -exec grep -h "components/" {} \; | sort | uniq -c | sort -nr)
echo "$components"
```

## üß™ Validation and Testing

### Component Integration Tests
```bash
#!/bin/bash
# scripts/test-component-integration.sh

set -e

echo "üß™ Testing Component Integration Across Projects"

# Test all project overlays with components
for project_dir in */; do
    if [ -d "$project_dir/overlays" ]; then
        echo "Testing project: $project_dir"
        
        for overlay in "$project_dir"/overlays/*/; do
            overlay_name=$(basename "$overlay")
            echo "  Testing overlay: $overlay_name"
            
            # Validate syntax
            kubectl kustomize "$overlay" --dry-run=client > /tmp/test-manifest.yaml || {
                echo "  ‚ùå Syntax validation failed"
                continue
            }
            
            # Check for required resources
            required_resources=("Deployment" "Service")
            for resource in "${required_resources[@]}"; do
                if ! grep -q "kind: $resource" /tmp/test-manifest.yaml; then
                    echo "  ‚ö†Ô∏è  Missing required resource: $resource"
                fi
            done
            
            # Check component labels are present
            if grep -q "component:" /tmp/test-manifest.yaml; then
                echo "  ‚úÖ Component labels found"
            else
                echo "  ‚ö†Ô∏è  No component labels found"
            fi
            
            echo "  ‚úÖ Overlay validation passed"
        done
        echo ""
    fi
done

rm -f /tmp/test-manifest.yaml
echo "üéâ All integration tests completed!"
```

### Component Consistency Check
```bash
#!/bin/bash
# scripts/check-component-consistency.sh

echo "üîç Component Consistency Check"
echo "============================="

# Check that all projects using the same component have consistent configurations
check_component_consistency() {
    local component_name=$1
    echo "Checking consistency for: $component_name"
    
    # Find all usages of this component
    users=$(find . -name "kustomization.yaml" -path "*/overlays/*" -exec grep -l "components.*$component_name" {} \;)
    
    echo "  Used by:"
    echo "$users" | sed 's/^/    /'
    
    # Check for configuration variations
    echo "  Configuration variations:"
    while IFS= read -r file; do
        project=$(echo "$file" | cut -d/ -f1-2)
        config=$(grep -A 20 "configMapGenerator:" "$file" | grep -A 10 "$component_name" || echo "No config")
        echo "    $project: $config"
    done <<< "$users"
    
    echo ""
}

# Check consistency for each component
component_list=(
    "monitoring"
    "postgresql"
    "security-policies"  
    "ingress"
)

for component in "${component_list[@]}"; do
    check_component_consistency "$component"
done
```

## üìà Benefits Achieved

### Quantitative Benefits
```
Configuration Reduction:
‚îú‚îÄ‚îÄ Before: 1,500+ lines across 5 projects
‚îú‚îÄ‚îÄ After: 400 lines + 800 lines in components  
‚îú‚îÄ‚îÄ Savings: 1,100 lines (73% reduction)
‚îî‚îÄ‚îÄ Reusability: 800 lines serve 5 projects

Maintenance Improvement:
‚îú‚îÄ‚îÄ Before: Update 5 files for monitoring changes
‚îú‚îÄ‚îÄ After: Update 1 component file  
‚îú‚îÄ‚îÄ Error Reduction: 80% fewer places for mistakes
‚îî‚îÄ‚îÄ Consistency: Guaranteed identical configurations
```

### Qualitative Benefits
```yaml
Before Component Extraction:
  problems:
    - configuration-drift: "Each project diverges over time"
    - maintenance-burden: "Updates require changing 5+ files"  
    - error-prone: "Copy-paste mistakes are common"
    - knowledge-silos: "Each team reimplements patterns"
    
After Component Extraction:
  benefits:
    - consistency: "All projects use identical patterns"
    - maintainability: "Update once, apply everywhere"  
    - reliability: "Components are tested and proven"
    - knowledge-sharing: "Best practices encoded in components"
    - rapid-deployment: "New projects get components instantly"
```

## üéØ Best Practices Summary

### ‚úÖ Component Extraction Guidelines

1. **Identify True Duplicates First**
```bash
# Good: Extract identical configurations
md5sum */overlays/*/monitoring.yaml | sort
# If hashes match, extract to component

# Bad: Force variations into one component
# Let natural variations guide component flexibility
```

2. **Design for Flexibility**
```yaml
# Good: Parameterized component
configMapGenerator:
  - name: component-config
    literals:
      - STORAGE_SIZE=20Gi  # Configurable
      
# Bad: Hard-coded component
spec:
  storage: 20Gi  # Fixed, not flexible
```

3. **Maintain Backward Compatibility**
```yaml
# Good: Gradual migration support
components:
  - ../components/monitoring-v1  # Legacy projects
  - ../components/monitoring-v2  # New projects
  
# Bad: Breaking change migration
# All projects must update simultaneously
```

4. **Test Component Integration**
```bash
# Good: Test with real consumer projects
kubectl kustomize overlays/production --dry-run=client

# Bad: Test components in isolation only
kubectl kustomize components/monitoring --dry-run=client  
```

### ‚ö†Ô∏è Common Extraction Pitfalls

1. **Over-Extraction**
```yaml
# Problem: Making everything a component
components:
  - ../components/single-configmap    # Too granular
  - ../components/one-secret          # Not worth it

# Solution: Extract meaningful functional units
components:
  - ../components/monitoring-stack    # Complete functionality
  - ../components/database-tier       # Logical grouping
```

2. **Under-Parameterization**
```yaml
# Problem: Component too rigid
spec:
  replicas: 3  # Fixed, works only for production

# Solution: Make it configurable
spec:
  replicas: $(REPLICA_COUNT)  # Flexible
```

## üéì Summary

### Key Skills Mastered
1. **Pattern Recognition**: Identifying extractable configurations across projects
2. **Component Design**: Creating flexible, reusable components
3. **Migration Strategy**: Systematic approach to refactoring existing projects
4. **Impact Measurement**: Quantifying the benefits of componentization

### Organizational Impact
- **73% Configuration Reduction**: Eliminated duplicate configurations
- **5x Maintenance Efficiency**: Update once, apply everywhere
- **Consistency Guarantee**: Identical configurations across projects
- **Knowledge Codification**: Best practices captured in reusable components

You've successfully transformed a duplicated, maintenance-heavy infrastructure into a clean, component-based architecture. This represents the culmination of Kustomize mastery - taking real-world complexity and organizing it into maintainable, reusable patterns that scale across your entire organization.

## üèÜ Congratulations!

You've completed the comprehensive Kustomize basics series! You now possess the skills to:

- Understand and create kustomization.yaml files
- Implement base and overlay architectures  
- Apply patches and transformations effectively
- Build and manage reusable components
- Extract common patterns from existing infrastructure
- Design scalable, maintainable Kubernetes configurations

These skills will serve as the foundation for advanced Kubernetes configuration management and GitOps workflows in your organization.